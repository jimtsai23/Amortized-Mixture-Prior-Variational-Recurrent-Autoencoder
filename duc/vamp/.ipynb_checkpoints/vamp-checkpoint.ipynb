{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.manifold import TSNE\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from ptb import PTB\n",
    "from vamp.model import vamp\n",
    "from utils import linear_anneal, log_Normal_diag, log_Normal_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "max_len = 32\n",
    "batch_size = 32\n",
    "#pseudo_size = 100\n",
    "splits = ['train', 'valid', 'test']\n",
    "\n",
    "# Penn TreeBank (PTB) dataset\n",
    "data_path = '../data'\n",
    "datasets = {split: PTB(root=data_path, split=split) for split in splits}\n",
    "pseudo_dataset = datasets['valid']#[:pseudo_size]\n",
    "#datasets['valid'] = datasets['valid'][pseudo_size:]\n",
    "\n",
    "# dataloader\n",
    "dataloaders = {split: DataLoader(datasets[split],\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=split=='train',\n",
    "                                    num_workers=cpu_count(),\n",
    "                                    pin_memory=torch.cuda.is_available())\n",
    "                                    for split in splits}\n",
    "\n",
    "symbols = datasets['train'].symbols\n",
    "\n",
    "pseudo_dataloader = DataLoader(pseudo_dataset,\n",
    "                                batch_size=3270,\n",
    "                                pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3370"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(datasets['valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamp model\n",
    "embedding_size = 300\n",
    "hidden_size = 256\n",
    "latent_dim = 32\n",
    "dropout_rate = 0.5\n",
    "model = vamp(vocab_size=datasets['train'].vocab_size,\n",
    "               embed_size=embedding_size,\n",
    "               time_step=max_len,\n",
    "               hidden_size=hidden_size,\n",
    "               z_dim=latent_dim,\n",
    "               dropout_rate=dropout_rate,\n",
    "               bos_idx=symbols['<bos>'],\n",
    "               eos_idx=symbols['<eos>'],\n",
    "               pad_idx=symbols['<pad>'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder to save model\n",
    "save_path = 'vamp'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pseudo input\n",
    "pseudo_inputs, _, _, pseudo_lengths = next(iter(pseudo_dataloader))\n",
    "pseudo_inputs = pseudo_inputs.to(device)\n",
    "pseudo_lengths = pseudo_lengths.to(device)\n",
    "\n",
    "pseudo_sorted_len, pseudo_sorted_idx = torch.sort(pseudo_lengths, descending=True)\n",
    "pseudo_inputs = pseudo_inputs[pseudo_sorted_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function\n",
    "learning_rate = 0.001\n",
    "criterion = nn.NLLLoss(size_average=False, ignore_index=symbols['<pad>'])\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# negative log likelihood\n",
    "def NLL(logp, target, length):\n",
    "    target = target[:, :torch.max(length).item()].contiguous().view(-1)\n",
    "    logp = logp.view(-1, logp.size(-1))\n",
    "    return criterion(logp, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(z_q):\n",
    "    z_p_mu, z_p_logvar = model.encoder(pseudo_inputs, pseudo_sorted_len)\n",
    "    z_q_expand = z_q.unsqueeze(1)\n",
    "    means = z_p_mu.unsqueeze(0)\n",
    "    logvars = z_p_logvar.unsqueeze(0)\n",
    "\n",
    "    a = log_Normal_diag(z_q_expand, means, logvars, dim=2) - math.log(3270)#pseudo_size)\n",
    "    a_max, _ = torch.max(a, 1)\n",
    "\n",
    "    log_prior = a_max + torch.log(torch.sum(torch.exp(a - a_max.unsqueeze(1)), 1))\n",
    "\n",
    "    \n",
    "    return log_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Batch 0000/1315, ELBO-Loss 194.3226, NLL-Loss 194.3198, KL-Loss 0.2864, KL-Weight 0.0100\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 151.1310, NLL-Loss 151.0530, KL-Loss 5.6523, KL-Weight 0.0138\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 154.1317, NLL-Loss 154.0564, KL-Loss 4.2778, KL-Weight 0.0176\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 130.0665, NLL-Loss 129.9464, KL-Loss 5.6132, KL-Weight 0.0214\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 131.2611, NLL-Loss 131.1598, KL-Loss 4.0190, KL-Weight 0.0252\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 124.2300, NLL-Loss 124.0941, KL-Loss 4.6842, KL-Weight 0.0290\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 132.3321, NLL-Loss 132.1871, KL-Loss 4.4185, KL-Weight 0.0328\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 130.1237, NLL-Loss 129.9765, KL-Loss 4.0221, KL-Weight 0.0366\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 124.1292, NLL-Loss 123.9802, KL-Loss 3.6858, KL-Weight 0.0404\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 106.4381, NLL-Loss 106.2583, KL-Loss 4.0660, KL-Weight 0.0442\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 116.2327, NLL-Loss 116.0300, KL-Loss 4.2208, KL-Weight 0.0480\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 114.3264, NLL-Loss 114.1171, KL-Loss 4.0387, KL-Weight 0.0518\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 121.4978, NLL-Loss 121.2490, KL-Loss 4.4729, KL-Weight 0.0556\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 126.0843, NLL-Loss 125.8555, KL-Loss 3.8489, KL-Weight 0.0594\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 111.6235, NLL-Loss 111.3662, KL-Loss 4.0690, KL-Weight 0.0632\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 124.7069, NLL-Loss 124.4732, KL-Loss 3.4868, KL-Weight 0.0670\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 118.2786, NLL-Loss 118.0098, KL-Loss 3.7950, KL-Weight 0.0708\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 109.6277, NLL-Loss 109.3510, KL-Loss 3.7081, KL-Weight 0.0746\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 121.5066, NLL-Loss 121.2318, KL-Loss 3.5027, KL-Weight 0.0784\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 120.5202, NLL-Loss 120.2207, KL-Loss 3.6410, KL-Weight 0.0822\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 110.5162, NLL-Loss 110.1833, KL-Loss 3.8684, KL-Weight 0.0860\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 114.1929, NLL-Loss 113.8234, KL-Loss 4.1130, KL-Weight 0.0898\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 123.5282, NLL-Loss 123.1663, KL-Loss 3.8638, KL-Weight 0.0937\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 112.4404, NLL-Loss 112.0768, KL-Loss 3.7308, KL-Weight 0.0975\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 122.4038, NLL-Loss 122.0110, KL-Loss 3.8799, KL-Weight 0.1013\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 117.0966, NLL-Loss 116.6885, KL-Loss 3.8852, KL-Weight 0.1051\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 117.1900, NLL-Loss 116.8290, KL-Loss 3.3163, KL-Weight 0.1089\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 126.4036, NLL-Loss 126.0321, KL-Loss 3.3799, KL-Weight 0.1099\n",
      "TRAIN Epoch 00/20, ELBO 123.3105, NLL 123.0771, KL 4.0205, PPL 447.2642\n",
      "VALID Epoch 00/20, ELBO 112.7956, NLL 112.4081, KL 3.5224, PPL 274.4885\n",
      "TEST Epoch 00/20, ELBO 111.5511, NLL 111.1619, KL 3.5384, PPL 257.4788\n",
      "Model saved at vamp/E00.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 120.7195, NLL-Loss 120.3280, KL-Loss 3.5592, KL-Weight 0.1100\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 120.1905, NLL-Loss 119.7601, KL-Loss 3.7819, KL-Weight 0.1138\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 120.9548, NLL-Loss 120.5338, KL-Loss 3.5806, KL-Weight 0.1176\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 124.9344, NLL-Loss 124.4950, KL-Loss 3.6194, KL-Weight 0.1214\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 110.2348, NLL-Loss 109.7293, KL-Loss 4.0374, KL-Weight 0.1252\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 111.1228, NLL-Loss 110.6822, KL-Loss 3.4153, KL-Weight 0.1290\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 126.5587, NLL-Loss 126.0983, KL-Loss 3.4661, KL-Weight 0.1328\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 112.5307, NLL-Loss 112.0691, KL-Loss 3.3786, KL-Weight 0.1366\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 110.9958, NLL-Loss 110.5033, KL-Loss 3.5078, KL-Weight 0.1404\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 114.4476, NLL-Loss 113.9595, KL-Loss 3.3844, KL-Weight 0.1442\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 114.7153, NLL-Loss 114.1998, KL-Loss 3.4825, KL-Weight 0.1480\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 104.7673, NLL-Loss 104.2446, KL-Loss 3.4427, KL-Weight 0.1518\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 126.6936, NLL-Loss 126.1679, KL-Loss 3.3779, KL-Weight 0.1556\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 104.9666, NLL-Loss 104.3998, KL-Loss 3.5546, KL-Weight 0.1594\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 119.1717, NLL-Loss 118.5565, KL-Loss 3.7689, KL-Weight 0.1632\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 112.3642, NLL-Loss 111.7975, KL-Loss 3.3926, KL-Weight 0.1670\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 101.8830, NLL-Loss 101.2980, KL-Loss 3.4247, KL-Weight 0.1708\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 107.2189, NLL-Loss 106.5505, KL-Loss 3.8270, KL-Weight 0.1746\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 122.5770, NLL-Loss 121.9994, KL-Loss 3.2370, KL-Weight 0.1784\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 103.7410, NLL-Loss 103.0763, KL-Loss 3.6477, KL-Weight 0.1822\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 112.0006, NLL-Loss 111.3087, KL-Loss 3.7192, KL-Weight 0.1860\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 126.9620, NLL-Loss 126.3436, KL-Loss 3.2571, KL-Weight 0.1898\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 120.8964, NLL-Loss 120.2189, KL-Loss 3.4986, KL-Weight 0.1937\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 111.3011, NLL-Loss 110.6145, KL-Loss 3.4771, KL-Weight 0.1975\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 96.2007, NLL-Loss 95.4840, KL-Loss 3.5613, KL-Weight 0.2013\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 106.6895, NLL-Loss 106.0285, KL-Loss 3.2234, KL-Weight 0.2051\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 117.2611, NLL-Loss 116.5307, KL-Loss 3.4974, KL-Weight 0.2089\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 116.1796, NLL-Loss 115.5167, KL-Loss 3.1575, KL-Weight 0.2099\n",
      "TRAIN Epoch 01/20, ELBO 111.0573, NLL 110.4994, KL 3.4979, PPL 239.7141\n",
      "VALID Epoch 01/20, ELBO 108.3011, NLL 107.5792, KL 3.4377, PPL 215.6589\n",
      "TEST Epoch 01/20, ELBO 107.1253, NLL 106.3990, KL 3.4585, PPL 202.9779\n",
      "Model saved at vamp/E01.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 102.7433, NLL-Loss 102.0240, KL-Loss 3.4253, KL-Weight 0.2100\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 106.7060, NLL-Loss 106.0141, KL-Loss 3.2361, KL-Weight 0.2138\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 105.2900, NLL-Loss 104.5577, KL-Loss 3.3655, KL-Weight 0.2176\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 99.9710, NLL-Loss 99.1924, KL-Loss 3.5165, KL-Weight 0.2214\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 104.5846, NLL-Loss 103.7869, KL-Loss 3.5419, KL-Weight 0.2252\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 110.9014, NLL-Loss 110.1086, KL-Loss 3.4617, KL-Weight 0.2290\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 119.1339, NLL-Loss 118.3537, KL-Loss 3.3513, KL-Weight 0.2328\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 99.2873, NLL-Loss 98.5364, KL-Loss 3.1735, KL-Weight 0.2366\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 111.0905, NLL-Loss 110.2792, KL-Loss 3.3744, KL-Weight 0.2404\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 100.6575, NLL-Loss 99.8691, KL-Loss 3.2282, KL-Weight 0.2442\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 102.8511, NLL-Loss 101.9958, KL-Loss 3.4484, KL-Weight 0.2480\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 99.7871, NLL-Loss 98.9147, KL-Loss 3.4646, KL-Weight 0.2518\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 109.8863, NLL-Loss 108.9510, KL-Loss 3.6590, KL-Weight 0.2556\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 111.0932, NLL-Loss 110.1971, KL-Loss 3.4541, KL-Weight 0.2594\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 110.9557, NLL-Loss 110.1188, KL-Loss 3.1795, KL-Weight 0.2632\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 90.1691, NLL-Loss 89.2232, KL-Loss 3.5423, KL-Weight 0.2670\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 98.6729, NLL-Loss 97.7346, KL-Loss 3.4644, KL-Weight 0.2708\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 105.9957, NLL-Loss 105.0676, KL-Loss 3.3795, KL-Weight 0.2746\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 87.6721, NLL-Loss 86.7076, KL-Loss 3.4640, KL-Weight 0.2784\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 97.6778, NLL-Loss 96.7318, KL-Loss 3.3517, KL-Weight 0.2822\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 98.7660, NLL-Loss 97.8020, KL-Loss 3.3702, KL-Weight 0.2860\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 102.9366, NLL-Loss 101.9844, KL-Loss 3.2850, KL-Weight 0.2898\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 106.5734, NLL-Loss 105.6211, KL-Loss 3.2428, KL-Weight 0.2937\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 102.3447, NLL-Loss 101.3064, KL-Loss 3.4908, KL-Weight 0.2975\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 98.6907, NLL-Loss 97.6491, KL-Loss 3.4575, KL-Weight 0.3013\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 105.3738, NLL-Loss 104.3859, KL-Loss 3.2386, KL-Weight 0.3051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Batch 1300/1315, ELBO-Loss 97.6386, NLL-Loss 96.5507, KL-Loss 3.5223, KL-Weight 0.3089\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 90.6798, NLL-Loss 89.6127, KL-Loss 3.4430, KL-Weight 0.3099\n",
      "TRAIN Epoch 02/20, ELBO 106.3165, NLL 105.4426, KL 3.3647, PPL 186.5481\n",
      "VALID Epoch 02/20, ELBO 106.1625, NLL 105.1356, KL 3.3127, PPL 190.8783\n",
      "TEST Epoch 02/20, ELBO 104.9136, NLL 103.8831, KL 3.3245, PPL 179.0139\n",
      "Model saved at vamp/E02.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 98.3328, NLL-Loss 97.3105, KL-Loss 3.2975, KL-Weight 0.3100\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 90.4694, NLL-Loss 89.3962, KL-Loss 3.4201, KL-Weight 0.3138\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 90.0658, NLL-Loss 88.9729, KL-Loss 3.4410, KL-Weight 0.3176\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 101.3129, NLL-Loss 100.2560, KL-Loss 3.2884, KL-Weight 0.3214\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 97.8575, NLL-Loss 96.8051, KL-Loss 3.2363, KL-Weight 0.3252\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 112.2665, NLL-Loss 111.1942, KL-Loss 3.2592, KL-Weight 0.3290\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 89.8081, NLL-Loss 88.6116, KL-Loss 3.5951, KL-Weight 0.3328\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 104.7553, NLL-Loss 103.6100, KL-Loss 3.4023, KL-Weight 0.3366\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 119.8393, NLL-Loss 118.7522, KL-Loss 3.1933, KL-Weight 0.3404\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 103.5129, NLL-Loss 102.3635, KL-Loss 3.3391, KL-Weight 0.3442\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 117.4487, NLL-Loss 116.3519, KL-Loss 3.1515, KL-Weight 0.3480\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 131.9828, NLL-Loss 130.8853, KL-Loss 3.1195, KL-Weight 0.3518\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 111.7220, NLL-Loss 110.6344, KL-Loss 3.0581, KL-Weight 0.3556\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 101.1326, NLL-Loss 99.8905, KL-Loss 3.4558, KL-Weight 0.3594\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 105.2231, NLL-Loss 104.0298, KL-Loss 3.2855, KL-Weight 0.3632\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 77.8223, NLL-Loss 76.5334, KL-Loss 3.5116, KL-Weight 0.3670\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 93.3634, NLL-Loss 92.1740, KL-Loss 3.2072, KL-Weight 0.3708\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 89.6076, NLL-Loss 88.3034, KL-Loss 3.4812, KL-Weight 0.3746\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 103.1522, NLL-Loss 101.8908, KL-Loss 3.3332, KL-Weight 0.3784\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 110.6752, NLL-Loss 109.4301, KL-Loss 3.2575, KL-Weight 0.3822\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 112.0083, NLL-Loss 110.8064, KL-Loss 3.1133, KL-Weight 0.3860\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 114.1066, NLL-Loss 112.8203, KL-Loss 3.2995, KL-Weight 0.3898\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 102.7958, NLL-Loss 101.4972, KL-Loss 3.2990, KL-Weight 0.3937\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 90.6469, NLL-Loss 89.2391, KL-Loss 3.5421, KL-Weight 0.3975\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 100.7031, NLL-Loss 99.3660, KL-Loss 3.3324, KL-Weight 0.4013\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 121.9741, NLL-Loss 120.7088, KL-Loss 3.1237, KL-Weight 0.4051\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 108.3446, NLL-Loss 107.0470, KL-Loss 3.1737, KL-Weight 0.4089\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 108.9200, NLL-Loss 107.4962, KL-Loss 3.4735, KL-Weight 0.4099\n",
      "TRAIN Epoch 03/20, ELBO 103.2180, NLL 102.0273, KL 3.3093, PPL 157.4856\n",
      "VALID Epoch 03/20, ELBO 105.2378, NLL 103.8869, KL 3.2949, PPL 179.3365\n",
      "TEST Epoch 03/20, ELBO 103.9234, NLL 102.5699, KL 3.3011, PPL 167.6523\n",
      "Model saved at vamp/E03.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 87.0860, NLL-Loss 85.6499, KL-Loss 3.5027, KL-Weight 0.4100\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 115.7680, NLL-Loss 114.4942, KL-Loss 3.0783, KL-Weight 0.4138\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 103.9597, NLL-Loss 102.6395, KL-Loss 3.1613, KL-Weight 0.4176\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 97.1875, NLL-Loss 95.7151, KL-Loss 3.4939, KL-Weight 0.4214\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 88.7520, NLL-Loss 87.3361, KL-Loss 3.3299, KL-Weight 0.4252\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 91.0892, NLL-Loss 89.6570, KL-Loss 3.3385, KL-Weight 0.4290\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 93.4216, NLL-Loss 92.0128, KL-Loss 3.2549, KL-Weight 0.4328\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 97.6361, NLL-Loss 96.2308, KL-Loss 3.2187, KL-Weight 0.4366\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 103.5370, NLL-Loss 102.0871, KL-Loss 3.2921, KL-Weight 0.4404\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 104.4319, NLL-Loss 102.9920, KL-Loss 3.2413, KL-Weight 0.4442\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 98.9146, NLL-Loss 97.4225, KL-Loss 3.3304, KL-Weight 0.4480\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 104.5013, NLL-Loss 103.0964, KL-Loss 3.1096, KL-Weight 0.4518\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 101.2360, NLL-Loss 99.6521, KL-Loss 3.4762, KL-Weight 0.4556\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 104.8514, NLL-Loss 103.3729, KL-Loss 3.2180, KL-Weight 0.4594\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 99.2375, NLL-Loss 97.7423, KL-Loss 3.2279, KL-Weight 0.4632\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 112.2905, NLL-Loss 110.8121, KL-Loss 3.1655, KL-Weight 0.4670\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 91.5575, NLL-Loss 89.9650, KL-Loss 3.3824, KL-Weight 0.4708\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 96.3581, NLL-Loss 94.7873, KL-Loss 3.3095, KL-Weight 0.4746\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 97.1184, NLL-Loss 95.5953, KL-Loss 3.1834, KL-Weight 0.4784\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 106.8958, NLL-Loss 105.2862, KL-Loss 3.3377, KL-Weight 0.4822\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 110.6387, NLL-Loss 109.0337, KL-Loss 3.3023, KL-Weight 0.4860\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 104.4040, NLL-Loss 102.7988, KL-Loss 3.2769, KL-Weight 0.4898\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 103.7224, NLL-Loss 102.0981, KL-Loss 3.2904, KL-Weight 0.4937\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 117.6891, NLL-Loss 116.1047, KL-Loss 3.1850, KL-Weight 0.4975\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 109.9535, NLL-Loss 108.3875, KL-Loss 3.1243, KL-Weight 0.5013\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 93.8539, NLL-Loss 92.1260, KL-Loss 3.4212, KL-Weight 0.5051\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 101.2651, NLL-Loss 99.6182, KL-Loss 3.2365, KL-Weight 0.5089\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 99.4755, NLL-Loss 97.8443, KL-Loss 3.1988, KL-Weight 0.5099\n",
      "TRAIN Epoch 04/20, ELBO 101.1620, NLL 99.6443, KL 3.2998, PPL 139.9332\n",
      "VALID Epoch 04/20, ELBO 104.6482, NLL 102.9696, KL 3.2913, PPL 171.3047\n",
      "TEST Epoch 04/20, ELBO 103.4533, NLL 101.7061, KL 3.4259, PPL 160.5739\n",
      "Model saved at vamp/E04.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 94.1313, NLL-Loss 92.3363, KL-Loss 3.5195, KL-Weight 0.5100\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 97.0085, NLL-Loss 95.2676, KL-Loss 3.3884, KL-Weight 0.5138\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 107.9597, NLL-Loss 106.3270, KL-Loss 3.1542, KL-Weight 0.5176\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 97.1121, NLL-Loss 95.4027, KL-Loss 3.2785, KL-Weight 0.5214\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 99.7027, NLL-Loss 98.0397, KL-Loss 3.1662, KL-Weight 0.5252\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 93.1255, NLL-Loss 91.3815, KL-Loss 3.2968, KL-Weight 0.5290\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 103.4293, NLL-Loss 101.6520, KL-Loss 3.3356, KL-Weight 0.5328\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 93.4208, NLL-Loss 91.7181, KL-Loss 3.1730, KL-Weight 0.5366\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 105.1621, NLL-Loss 103.4710, KL-Loss 3.1292, KL-Weight 0.5404\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 104.6749, NLL-Loss 103.0013, KL-Loss 3.0752, KL-Weight 0.5442\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 89.5669, NLL-Loss 87.7475, KL-Loss 3.3201, KL-Weight 0.5480\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 102.5834, NLL-Loss 100.8434, KL-Loss 3.1531, KL-Weight 0.5518\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 102.2182, NLL-Loss 100.4862, KL-Loss 3.1172, KL-Weight 0.5556\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 109.3357, NLL-Loss 107.5410, KL-Loss 3.2081, KL-Weight 0.5594\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 89.6851, NLL-Loss 87.8246, KL-Loss 3.3033, KL-Weight 0.5632\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 103.2626, NLL-Loss 101.3934, KL-Loss 3.2965, KL-Weight 0.5670\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 111.4782, NLL-Loss 109.6560, KL-Loss 3.1922, KL-Weight 0.5708\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 100.7794, NLL-Loss 98.9255, KL-Loss 3.2261, KL-Weight 0.5746\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 109.5142, NLL-Loss 107.6828, KL-Loss 3.1661, KL-Weight 0.5784\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 103.2581, NLL-Loss 101.3089, KL-Loss 3.3477, KL-Weight 0.5822\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 109.0297, NLL-Loss 107.1423, KL-Loss 3.2206, KL-Weight 0.5860\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 92.9772, NLL-Loss 90.9383, KL-Loss 3.4566, KL-Weight 0.5898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Batch 1100/1315, ELBO-Loss 90.0683, NLL-Loss 87.9507, KL-Loss 3.5671, KL-Weight 0.5937\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 105.6851, NLL-Loss 103.7522, KL-Loss 3.2353, KL-Weight 0.5975\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 103.7541, NLL-Loss 101.8535, KL-Loss 3.1611, KL-Weight 0.6013\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 111.8822, NLL-Loss 110.0169, KL-Loss 3.0827, KL-Weight 0.6051\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 100.2209, NLL-Loss 98.2461, KL-Loss 3.2434, KL-Weight 0.6089\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 96.4501, NLL-Loss 94.4711, KL-Loss 3.2447, KL-Weight 0.6099\n",
      "TRAIN Epoch 05/20, ELBO 99.5171, NLL 97.6342, KL 3.3586, PPL 126.6578\n",
      "VALID Epoch 05/20, ELBO 106.1652, NLL 104.1530, KL 3.2987, PPL 181.7362\n",
      "TEST Epoch 05/20, ELBO 104.8028, NLL 102.7742, KL 3.3255, PPL 169.3714\n",
      "Model saved at vamp/E05.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 100.4857, NLL-Loss 98.5371, KL-Loss 3.1944, KL-Weight 0.6100\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 106.7816, NLL-Loss 104.8742, KL-Loss 3.1075, KL-Weight 0.6138\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 92.0239, NLL-Loss 90.0116, KL-Loss 3.2583, KL-Weight 0.6176\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 93.5543, NLL-Loss 91.5999, KL-Loss 3.1451, KL-Weight 0.6214\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 107.3466, NLL-Loss 105.4395, KL-Loss 3.0502, KL-Weight 0.6252\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 118.7287, NLL-Loss 116.8466, KL-Loss 2.9922, KL-Weight 0.6290\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 95.5206, NLL-Loss 93.5378, KL-Loss 3.1334, KL-Weight 0.6328\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 102.3027, NLL-Loss 100.1801, KL-Loss 3.3342, KL-Weight 0.6366\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 96.2428, NLL-Loss 94.1429, KL-Loss 3.2789, KL-Weight 0.6404\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 113.3131, NLL-Loss 111.2989, KL-Loss 3.1266, KL-Weight 0.6442\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 94.0187, NLL-Loss 91.8574, KL-Loss 3.3352, KL-Weight 0.6480\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 87.7514, NLL-Loss 85.6109, KL-Loss 3.2838, KL-Weight 0.6518\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 96.1461, NLL-Loss 94.1163, KL-Loss 3.0960, KL-Weight 0.6556\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 85.0243, NLL-Loss 82.8510, KL-Loss 3.2958, KL-Weight 0.6594\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 107.9115, NLL-Loss 105.7763, KL-Loss 3.2193, KL-Weight 0.6632\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 98.2746, NLL-Loss 96.1296, KL-Loss 3.2158, KL-Weight 0.6670\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 98.5571, NLL-Loss 96.4009, KL-Loss 3.2142, KL-Weight 0.6708\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 88.4387, NLL-Loss 86.0169, KL-Loss 3.5896, KL-Weight 0.6746\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 107.0250, NLL-Loss 104.8725, KL-Loss 3.1728, KL-Weight 0.6784\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 109.8903, NLL-Loss 107.6400, KL-Loss 3.2983, KL-Weight 0.6822\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 100.2103, NLL-Loss 97.8752, KL-Loss 3.4037, KL-Weight 0.6860\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 105.8290, NLL-Loss 103.5922, KL-Loss 3.2424, KL-Weight 0.6898\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 103.8724, NLL-Loss 100.0147, KL-Loss 5.5614, KL-Weight 0.6937\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 102.0941, NLL-Loss 99.8444, KL-Loss 3.2255, KL-Weight 0.6975\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 94.3730, NLL-Loss 92.1616, KL-Loss 3.1534, KL-Weight 0.7013\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 87.8604, NLL-Loss 85.4461, KL-Loss 3.4243, KL-Weight 0.7051\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 95.1084, NLL-Loss 92.7185, KL-Loss 3.3715, KL-Weight 0.7089\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 98.0617, NLL-Loss 95.6284, KL-Loss 3.4276, KL-Weight 0.7099\n",
      "TRAIN Epoch 06/20, ELBO 98.3427, NLL 96.0815, KL 3.4286, PPL 117.2714\n",
      "VALID Epoch 06/20, ELBO 104.6955, NLL 102.3578, KL 3.2925, PPL 166.1489\n",
      "TEST Epoch 06/20, ELBO 103.1996, NLL 100.8477, KL 3.3125, PPL 153.8367\n",
      "Model saved at vamp/E06.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 98.8728, NLL-Loss 96.5853, KL-Loss 3.2218, KL-Weight 0.7100\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 84.9701, NLL-Loss 82.5597, KL-Loss 3.3769, KL-Weight 0.7138\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 93.7515, NLL-Loss 91.3169, KL-Loss 3.3928, KL-Weight 0.7176\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 103.6535, NLL-Loss 101.2824, KL-Loss 3.2867, KL-Weight 0.7214\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 96.7365, NLL-Loss 94.4952, KL-Loss 3.0905, KL-Weight 0.7252\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 92.6183, NLL-Loss 90.1247, KL-Loss 3.4205, KL-Weight 0.7290\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 90.8709, NLL-Loss 88.5140, KL-Loss 3.2162, KL-Weight 0.7328\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 86.2248, NLL-Loss 83.7178, KL-Loss 3.4034, KL-Weight 0.7366\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 91.9686, NLL-Loss 89.5171, KL-Loss 3.3109, KL-Weight 0.7404\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 105.9322, NLL-Loss 103.5266, KL-Loss 3.2324, KL-Weight 0.7442\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 87.2796, NLL-Loss 84.7002, KL-Loss 3.4482, KL-Weight 0.7480\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 96.2236, NLL-Loss 93.6960, KL-Loss 3.3619, KL-Weight 0.7518\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 92.0213, NLL-Loss 89.3300, KL-Loss 3.5617, KL-Weight 0.7556\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 92.9237, NLL-Loss 90.4863, KL-Loss 3.2095, KL-Weight 0.7594\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 96.4560, NLL-Loss 93.8563, KL-Loss 3.4062, KL-Weight 0.7632\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 116.6153, NLL-Loss 114.2962, KL-Loss 3.0235, KL-Weight 0.7670\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 107.2998, NLL-Loss 104.8018, KL-Loss 3.2406, KL-Weight 0.7708\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 97.5574, NLL-Loss 95.0971, KL-Loss 3.1761, KL-Weight 0.7746\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 100.5863, NLL-Loss 98.1459, KL-Loss 3.1350, KL-Weight 0.7784\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 104.4466, NLL-Loss 102.0127, KL-Loss 3.1115, KL-Weight 0.7822\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 90.4965, NLL-Loss 87.9660, KL-Loss 3.2193, KL-Weight 0.7860\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 91.8607, NLL-Loss 89.3407, KL-Loss 3.1905, KL-Weight 0.7898\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 101.5676, NLL-Loss 98.9489, KL-Loss 3.2995, KL-Weight 0.7937\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 104.3786, NLL-Loss 101.8508, KL-Loss 3.1699, KL-Weight 0.7975\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 88.4437, NLL-Loss 85.7914, KL-Loss 3.3103, KL-Weight 0.8013\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 102.1087, NLL-Loss 99.4203, KL-Loss 3.3394, KL-Weight 0.8051\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 98.9766, NLL-Loss 96.3296, KL-Loss 3.2726, KL-Weight 0.8089\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 95.1734, NLL-Loss 92.4704, KL-Loss 3.3373, KL-Weight 0.8099\n",
      "TRAIN Epoch 07/20, ELBO 97.6207, NLL 95.0523, KL 3.3790, PPL 111.4368\n",
      "VALID Epoch 07/20, ELBO 104.9654, NLL 102.3012, KL 3.2891, PPL 165.6800\n",
      "TEST Epoch 07/20, ELBO 103.5291, NLL 100.8501, KL 3.3074, PPL 153.8549\n",
      "Model saved at vamp/E07.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 93.0973, NLL-Loss 90.4264, KL-Loss 3.2975, KL-Weight 0.8100\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 80.8496, NLL-Loss 77.8861, KL-Loss 3.6416, KL-Weight 0.8138\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 96.9103, NLL-Loss 94.1780, KL-Loss 3.3419, KL-Weight 0.8176\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 110.7534, NLL-Loss 108.0790, KL-Loss 3.2558, KL-Weight 0.8214\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 92.9488, NLL-Loss 90.2073, KL-Loss 3.3221, KL-Weight 0.8252\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 98.8281, NLL-Loss 96.2116, KL-Loss 3.1562, KL-Weight 0.8290\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 104.0098, NLL-Loss 101.4062, KL-Loss 3.1262, KL-Weight 0.8328\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 103.8147, NLL-Loss 101.0848, KL-Loss 3.2630, KL-Weight 0.8366\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 96.9528, NLL-Loss 94.1092, KL-Loss 3.3835, KL-Weight 0.8404\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 95.8449, NLL-Loss 92.8956, KL-Loss 3.4935, KL-Weight 0.8442\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 98.2091, NLL-Loss 95.2767, KL-Loss 3.4579, KL-Weight 0.8480\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 98.2290, NLL-Loss 95.4479, KL-Loss 3.2648, KL-Weight 0.8518\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 94.3487, NLL-Loss 91.6537, KL-Loss 3.1497, KL-Weight 0.8556\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 102.9338, NLL-Loss 100.0841, KL-Loss 3.3158, KL-Weight 0.8594\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 93.5617, NLL-Loss 90.7777, KL-Loss 3.2252, KL-Weight 0.8632\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 106.6962, NLL-Loss 104.1163, KL-Loss 2.9755, KL-Weight 0.8670\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 87.5778, NLL-Loss 84.3752, KL-Loss 3.6776, KL-Weight 0.8708\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 112.1000, NLL-Loss 109.3564, KL-Loss 3.1368, KL-Weight 0.8746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Batch 0900/1315, ELBO-Loss 98.0776, NLL-Loss 95.0784, KL-Loss 3.4143, KL-Weight 0.8784\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 89.5886, NLL-Loss 86.6516, KL-Loss 3.3290, KL-Weight 0.8822\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 95.6791, NLL-Loss 92.6557, KL-Loss 3.4122, KL-Weight 0.8860\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 98.6471, NLL-Loss 95.8609, KL-Loss 3.1311, KL-Weight 0.8898\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 91.1962, NLL-Loss 88.2274, KL-Loss 3.3221, KL-Weight 0.8937\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 93.6244, NLL-Loss 90.4865, KL-Loss 3.4965, KL-Weight 0.8975\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 92.9863, NLL-Loss 90.1286, KL-Loss 3.1708, KL-Weight 0.9013\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 89.2787, NLL-Loss 86.2232, KL-Loss 3.3761, KL-Weight 0.9051\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 92.9040, NLL-Loss 89.8105, KL-Loss 3.4037, KL-Weight 0.9089\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 94.6638, NLL-Loss 91.5242, KL-Loss 3.4504, KL-Weight 0.9099\n",
      "TRAIN Epoch 08/20, ELBO 96.8429, NLL 93.9276, KL 3.3916, PPL 105.3916\n",
      "VALID Epoch 08/20, ELBO 105.1178, NLL 102.1228, KL 3.2912, PPL 164.2094\n",
      "TEST Epoch 08/20, ELBO 103.5548, NLL 100.5146, KL 3.3409, PPL 151.2990\n",
      "Model saved at vamp/E08.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 99.1332, NLL-Loss 96.1704, KL-Loss 3.2559, KL-Weight 0.9100\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 95.1780, NLL-Loss 92.0507, KL-Loss 3.4223, KL-Weight 0.9138\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 88.6077, NLL-Loss 85.3099, KL-Loss 3.5939, KL-Weight 0.9176\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 89.7013, NLL-Loss 86.6660, KL-Loss 3.2942, KL-Weight 0.9214\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 105.4982, NLL-Loss 102.4276, KL-Loss 3.3187, KL-Weight 0.9252\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 102.4080, NLL-Loss 99.3884, KL-Loss 3.2503, KL-Weight 0.9290\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 91.6006, NLL-Loss 88.4183, KL-Loss 3.4114, KL-Weight 0.9328\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 110.6306, NLL-Loss 107.7461, KL-Loss 3.0796, KL-Weight 0.9366\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 81.8108, NLL-Loss 78.3803, KL-Loss 3.6478, KL-Weight 0.9404\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 91.8592, NLL-Loss 88.7548, KL-Loss 3.2878, KL-Weight 0.9442\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 105.7560, NLL-Loss 102.7279, KL-Loss 3.1942, KL-Weight 0.9480\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 91.9628, NLL-Loss 88.8643, KL-Loss 3.2553, KL-Weight 0.9518\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 93.4182, NLL-Loss 90.2140, KL-Loss 3.3530, KL-Weight 0.9556\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 74.4612, NLL-Loss 71.1381, KL-Loss 3.4636, KL-Weight 0.9594\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 87.8285, NLL-Loss 84.7086, KL-Loss 3.2390, KL-Weight 0.9632\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 96.9315, NLL-Loss 93.7879, KL-Loss 3.2508, KL-Weight 0.9670\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 92.5512, NLL-Loss 89.4056, KL-Loss 3.2401, KL-Weight 0.9708\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 97.6531, NLL-Loss 94.3751, KL-Loss 3.3633, KL-Weight 0.9746\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 86.5631, NLL-Loss 83.2281, KL-Loss 3.4084, KL-Weight 0.9784\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 105.7385, NLL-Loss 102.6101, KL-Loss 3.1850, KL-Weight 0.9822\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 105.9371, NLL-Loss 102.9943, KL-Loss 2.9845, KL-Weight 0.9860\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 97.8360, NLL-Loss 94.5934, KL-Loss 3.2759, KL-Weight 0.9898\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 108.6599, NLL-Loss 105.5098, KL-Loss 3.1702, KL-Weight 0.9937\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 86.2307, NLL-Loss 82.7497, KL-Loss 3.4900, KL-Weight 0.9975\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 92.7344, NLL-Loss 89.4928, KL-Loss 3.2417, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 93.2524, NLL-Loss 89.9529, KL-Loss 3.2995, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 89.3158, NLL-Loss 85.7784, KL-Loss 3.5374, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 105.6166, NLL-Loss 102.4413, KL-Loss 3.1754, KL-Weight 1.0000\n",
      "TRAIN Epoch 09/20, ELBO 96.0174, NLL 92.8258, KL 3.3269, PPL 99.7882\n",
      "VALID Epoch 09/20, ELBO 105.3415, NLL 102.0547, KL 3.2867, PPL 163.6522\n",
      "TEST Epoch 09/20, ELBO 103.5952, NLL 100.3017, KL 3.2935, PPL 149.6993\n",
      "Model saved at vamp/E09.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 90.7523, NLL-Loss 87.3716, KL-Loss 3.3806, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 89.5885, NLL-Loss 86.4275, KL-Loss 3.1610, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 84.8356, NLL-Loss 81.5794, KL-Loss 3.2562, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 99.2388, NLL-Loss 96.0861, KL-Loss 3.1526, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 93.0898, NLL-Loss 89.7286, KL-Loss 3.3612, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 87.9681, NLL-Loss 84.7317, KL-Loss 3.2363, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 94.9711, NLL-Loss 91.7019, KL-Loss 3.2693, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 74.9385, NLL-Loss 71.4648, KL-Loss 3.4737, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 90.8054, NLL-Loss 87.5249, KL-Loss 3.2805, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 93.4932, NLL-Loss 90.2950, KL-Loss 3.1982, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 89.9471, NLL-Loss 86.7690, KL-Loss 3.1780, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 87.7589, NLL-Loss 84.3537, KL-Loss 3.4051, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 99.1083, NLL-Loss 95.7089, KL-Loss 3.3994, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 91.7193, NLL-Loss 88.3184, KL-Loss 3.4008, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 100.9271, NLL-Loss 97.7636, KL-Loss 3.1635, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 91.5048, NLL-Loss 88.0976, KL-Loss 3.4072, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 104.3681, NLL-Loss 101.0923, KL-Loss 3.2758, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 96.7452, NLL-Loss 93.5135, KL-Loss 3.2317, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 96.5581, NLL-Loss 93.4810, KL-Loss 3.0770, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 86.5411, NLL-Loss 83.2820, KL-Loss 3.2591, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 106.8698, NLL-Loss 103.7223, KL-Loss 3.1475, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 100.3046, NLL-Loss 97.1286, KL-Loss 3.1760, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 105.1909, NLL-Loss 102.2096, KL-Loss 2.9813, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 111.5415, NLL-Loss 108.5262, KL-Loss 3.0153, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 88.7650, NLL-Loss 85.3648, KL-Loss 3.4002, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 90.6569, NLL-Loss 87.3381, KL-Loss 3.3188, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 77.8297, NLL-Loss 74.2867, KL-Loss 3.5430, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 95.9404, NLL-Loss 92.7209, KL-Loss 3.2196, KL-Weight 1.0000\n",
      "TRAIN Epoch 10/20, ELBO 94.1507, NLL 90.8641, KL 3.2866, PPL 90.5380\n",
      "VALID Epoch 10/20, ELBO 105.0632, NLL 101.7711, KL 3.2921, PPL 161.3502\n",
      "TEST Epoch 10/20, ELBO 103.2186, NLL 99.9092, KL 3.3094, PPL 146.7935\n",
      "Model saved at vamp/E10.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 91.6277, NLL-Loss 88.4066, KL-Loss 3.2211, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 99.7585, NLL-Loss 96.6775, KL-Loss 3.0810, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 83.7931, NLL-Loss 80.4198, KL-Loss 3.3732, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 80.0125, NLL-Loss 76.6485, KL-Loss 3.3640, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 83.2581, NLL-Loss 79.7194, KL-Loss 3.5387, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 104.7806, NLL-Loss 101.5173, KL-Loss 3.2633, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 96.4119, NLL-Loss 93.0548, KL-Loss 3.3571, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 100.7038, NLL-Loss 97.4423, KL-Loss 3.2615, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 94.3522, NLL-Loss 90.7066, KL-Loss 3.6455, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 102.5121, NLL-Loss 99.2872, KL-Loss 3.2249, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 90.2523, NLL-Loss 86.8914, KL-Loss 3.3610, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 103.2023, NLL-Loss 99.9583, KL-Loss 3.2440, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 102.9135, NLL-Loss 99.6311, KL-Loss 3.2824, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 94.9806, NLL-Loss 91.6880, KL-Loss 3.2926, KL-Weight 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Batch 0700/1315, ELBO-Loss 85.4081, NLL-Loss 82.1061, KL-Loss 3.3020, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 90.4294, NLL-Loss 87.2167, KL-Loss 3.2127, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 82.3114, NLL-Loss 78.6145, KL-Loss 3.6969, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 95.2998, NLL-Loss 91.9921, KL-Loss 3.3077, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 107.7883, NLL-Loss 104.8321, KL-Loss 2.9561, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 93.1086, NLL-Loss 89.7954, KL-Loss 3.3132, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 99.7430, NLL-Loss 96.4584, KL-Loss 3.2846, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 79.1667, NLL-Loss 75.7772, KL-Loss 3.3896, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 87.7488, NLL-Loss 84.4558, KL-Loss 3.2930, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 92.7704, NLL-Loss 89.4341, KL-Loss 3.3363, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 92.0294, NLL-Loss 88.6179, KL-Loss 3.4115, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 99.8744, NLL-Loss 96.6609, KL-Loss 3.2135, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 88.2571, NLL-Loss 84.8874, KL-Loss 3.3697, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 96.5052, NLL-Loss 93.2853, KL-Loss 3.2198, KL-Weight 1.0000\n",
      "TRAIN Epoch 11/20, ELBO 93.2926, NLL 90.0039, KL 3.2887, PPL 86.7574\n",
      "VALID Epoch 11/20, ELBO 105.0494, NLL 101.7621, KL 3.2872, PPL 161.2780\n",
      "TEST Epoch 11/20, ELBO 103.2014, NLL 99.8990, KL 3.3024, PPL 146.7183\n",
      "Model saved at vamp/E11.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 97.9117, NLL-Loss 94.7096, KL-Loss 3.2022, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 80.7299, NLL-Loss 77.3758, KL-Loss 3.3541, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 87.4463, NLL-Loss 84.0654, KL-Loss 3.3809, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 85.9277, NLL-Loss 82.6148, KL-Loss 3.3129, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 88.2804, NLL-Loss 84.9401, KL-Loss 3.3403, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 94.6357, NLL-Loss 91.3748, KL-Loss 3.2609, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 84.7705, NLL-Loss 81.3289, KL-Loss 3.4416, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 93.3840, NLL-Loss 90.1249, KL-Loss 3.2591, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 99.0754, NLL-Loss 95.7915, KL-Loss 3.2839, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 84.5267, NLL-Loss 81.1612, KL-Loss 3.3656, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 84.3672, NLL-Loss 80.8740, KL-Loss 3.4932, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 111.9045, NLL-Loss 108.7613, KL-Loss 3.1432, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 89.9387, NLL-Loss 86.6621, KL-Loss 3.2765, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 89.3296, NLL-Loss 85.9290, KL-Loss 3.4006, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 91.9681, NLL-Loss 88.6006, KL-Loss 3.3675, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 96.1071, NLL-Loss 92.7961, KL-Loss 3.3110, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 87.9700, NLL-Loss 84.6965, KL-Loss 3.2735, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 104.8528, NLL-Loss 101.5856, KL-Loss 3.2672, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 88.8520, NLL-Loss 85.6207, KL-Loss 3.2313, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 86.2711, NLL-Loss 82.9899, KL-Loss 3.2813, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 87.2427, NLL-Loss 84.0374, KL-Loss 3.2053, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 98.2847, NLL-Loss 95.0239, KL-Loss 3.2608, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 86.8770, NLL-Loss 83.5636, KL-Loss 3.3134, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 86.6621, NLL-Loss 83.2942, KL-Loss 3.3678, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 76.9438, NLL-Loss 73.4862, KL-Loss 3.4576, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 78.9036, NLL-Loss 75.5023, KL-Loss 3.4013, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 93.5468, NLL-Loss 90.3247, KL-Loss 3.2222, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 117.0406, NLL-Loss 113.7391, KL-Loss 3.3015, KL-Weight 1.0000\n",
      "TRAIN Epoch 12/20, ELBO 92.2185, NLL 88.9360, KL 3.2825, PPL 82.2827\n",
      "VALID Epoch 12/20, ELBO 104.8701, NLL 101.5852, KL 3.2849, PPL 159.8587\n",
      "TEST Epoch 12/20, ELBO 103.0480, NLL 99.7339, KL 3.3141, PPL 145.5143\n",
      "Model saved at vamp/E12.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 96.0924, NLL-Loss 92.7914, KL-Loss 3.3010, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 105.0626, NLL-Loss 102.0308, KL-Loss 3.0318, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 87.1529, NLL-Loss 83.8967, KL-Loss 3.2562, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 92.7218, NLL-Loss 89.4404, KL-Loss 3.2815, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 90.8151, NLL-Loss 87.4613, KL-Loss 3.3538, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 80.5190, NLL-Loss 77.0514, KL-Loss 3.4675, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 90.5712, NLL-Loss 87.4138, KL-Loss 3.1574, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 80.7270, NLL-Loss 77.4368, KL-Loss 3.2902, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 96.0536, NLL-Loss 92.7897, KL-Loss 3.2639, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 97.8645, NLL-Loss 94.6248, KL-Loss 3.2397, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 90.4805, NLL-Loss 87.1057, KL-Loss 3.3748, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 90.2974, NLL-Loss 86.9947, KL-Loss 3.3027, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 102.1876, NLL-Loss 98.8772, KL-Loss 3.3104, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 97.1903, NLL-Loss 93.9557, KL-Loss 3.2346, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 100.3798, NLL-Loss 97.1989, KL-Loss 3.1809, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 101.2218, NLL-Loss 98.0409, KL-Loss 3.1808, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 96.3020, NLL-Loss 92.8508, KL-Loss 3.4512, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 91.0179, NLL-Loss 87.7055, KL-Loss 3.3123, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 84.1728, NLL-Loss 80.8119, KL-Loss 3.3610, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 102.5339, NLL-Loss 99.1626, KL-Loss 3.3713, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 92.5986, NLL-Loss 89.1790, KL-Loss 3.4196, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 98.5469, NLL-Loss 95.1433, KL-Loss 3.4037, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 95.7123, NLL-Loss 92.5410, KL-Loss 3.1713, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 99.7936, NLL-Loss 96.6068, KL-Loss 3.1868, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 100.2759, NLL-Loss 97.0459, KL-Loss 3.2299, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 89.2062, NLL-Loss 85.9608, KL-Loss 3.2454, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 93.2362, NLL-Loss 90.0760, KL-Loss 3.1602, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 102.9171, NLL-Loss 99.4057, KL-Loss 3.5114, KL-Weight 1.0000\n",
      "TRAIN Epoch 13/20, ELBO 91.7951, NLL 88.5122, KL 3.2829, PPL 80.5714\n",
      "VALID Epoch 13/20, ELBO 104.9834, NLL 101.6962, KL 3.2871, PPL 160.7480\n",
      "TEST Epoch 13/20, ELBO 103.0292, NLL 99.7352, KL 3.2940, PPL 145.5232\n",
      "Model saved at vamp/E13.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 94.7387, NLL-Loss 91.5170, KL-Loss 3.2217, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 82.6253, NLL-Loss 79.1698, KL-Loss 3.4555, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 87.7577, NLL-Loss 84.4340, KL-Loss 3.3237, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 92.3040, NLL-Loss 88.9013, KL-Loss 3.4027, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 100.9378, NLL-Loss 97.7306, KL-Loss 3.2072, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 94.6943, NLL-Loss 91.3934, KL-Loss 3.3008, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 94.6873, NLL-Loss 91.4830, KL-Loss 3.2043, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 80.9872, NLL-Loss 77.6594, KL-Loss 3.3279, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 93.3070, NLL-Loss 89.9145, KL-Loss 3.3926, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 82.5120, NLL-Loss 79.2506, KL-Loss 3.2613, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 99.0211, NLL-Loss 95.9409, KL-Loss 3.0802, KL-Weight 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Batch 0550/1315, ELBO-Loss 86.4683, NLL-Loss 83.2788, KL-Loss 3.1894, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 86.2088, NLL-Loss 82.7845, KL-Loss 3.4243, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 93.6211, NLL-Loss 90.2452, KL-Loss 3.3758, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 74.4727, NLL-Loss 71.0250, KL-Loss 3.4477, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 91.8676, NLL-Loss 88.5644, KL-Loss 3.3032, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 72.3415, NLL-Loss 68.9026, KL-Loss 3.4389, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 88.3678, NLL-Loss 84.9998, KL-Loss 3.3680, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 79.8273, NLL-Loss 76.2163, KL-Loss 3.6111, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 95.0549, NLL-Loss 91.8260, KL-Loss 3.2289, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 84.5806, NLL-Loss 81.2123, KL-Loss 3.3683, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 90.3538, NLL-Loss 87.1282, KL-Loss 3.2256, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 74.0950, NLL-Loss 70.5776, KL-Loss 3.5174, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 86.5882, NLL-Loss 83.3520, KL-Loss 3.2362, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 91.9119, NLL-Loss 88.5058, KL-Loss 3.4060, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 94.0966, NLL-Loss 90.8684, KL-Loss 3.2282, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 84.8122, NLL-Loss 81.5588, KL-Loss 3.2535, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 103.4187, NLL-Loss 100.2464, KL-Loss 3.1723, KL-Weight 1.0000\n",
      "TRAIN Epoch 14/20, ELBO 91.2129, NLL 87.9316, KL 3.2812, PPL 78.2850\n",
      "VALID Epoch 14/20, ELBO 104.9005, NLL 101.6164, KL 3.2842, PPL 160.1078\n",
      "TEST Epoch 14/20, ELBO 103.0066, NLL 99.6871, KL 3.3195, PPL 145.1741\n",
      "Model saved at vamp/E14.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 87.9442, NLL-Loss 84.7997, KL-Loss 3.1446, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 87.3720, NLL-Loss 84.1267, KL-Loss 3.2453, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 85.9649, NLL-Loss 82.6594, KL-Loss 3.3055, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 81.8897, NLL-Loss 78.5345, KL-Loss 3.3552, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 100.8865, NLL-Loss 97.6356, KL-Loss 3.2509, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 83.7909, NLL-Loss 80.3336, KL-Loss 3.4573, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 91.0941, NLL-Loss 87.8582, KL-Loss 3.2359, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 98.2799, NLL-Loss 94.8637, KL-Loss 3.4163, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 89.8882, NLL-Loss 86.3453, KL-Loss 3.5430, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 89.1807, NLL-Loss 85.9664, KL-Loss 3.2143, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 88.9896, NLL-Loss 85.6032, KL-Loss 3.3864, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 92.5370, NLL-Loss 89.2311, KL-Loss 3.3059, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 101.6478, NLL-Loss 98.5531, KL-Loss 3.0947, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 97.9284, NLL-Loss 94.6527, KL-Loss 3.2756, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 81.1795, NLL-Loss 77.8831, KL-Loss 3.2964, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 81.9509, NLL-Loss 78.4803, KL-Loss 3.4706, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 101.3679, NLL-Loss 98.0428, KL-Loss 3.3251, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 104.0209, NLL-Loss 100.8947, KL-Loss 3.1262, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 94.0595, NLL-Loss 90.7725, KL-Loss 3.2870, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 96.2593, NLL-Loss 93.0390, KL-Loss 3.2203, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 96.5295, NLL-Loss 93.2253, KL-Loss 3.3042, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 91.3181, NLL-Loss 87.9561, KL-Loss 3.3621, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 85.9620, NLL-Loss 82.6447, KL-Loss 3.3173, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 77.9964, NLL-Loss 74.7167, KL-Loss 3.2797, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 84.9765, NLL-Loss 81.6041, KL-Loss 3.3724, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 85.3830, NLL-Loss 82.1781, KL-Loss 3.2048, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 86.8896, NLL-Loss 83.7550, KL-Loss 3.1347, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 91.6302, NLL-Loss 88.2878, KL-Loss 3.3424, KL-Weight 1.0000\n",
      "TRAIN Epoch 15/20, ELBO 91.0297, NLL 87.7503, KL 3.2794, PPL 77.5842\n",
      "VALID Epoch 15/20, ELBO 104.9161, NLL 101.6312, KL 3.2849, PPL 160.2265\n",
      "TEST Epoch 15/20, ELBO 102.9781, NLL 99.6600, KL 3.3180, PPL 144.9784\n",
      "Model saved at vamp/E15.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 92.1745, NLL-Loss 89.0102, KL-Loss 3.1643, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 82.2201, NLL-Loss 78.7583, KL-Loss 3.4618, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 79.0747, NLL-Loss 75.6774, KL-Loss 3.3973, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 92.5668, NLL-Loss 89.3930, KL-Loss 3.1738, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 97.9887, NLL-Loss 94.5580, KL-Loss 3.4307, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 97.6645, NLL-Loss 94.5326, KL-Loss 3.1319, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 84.3655, NLL-Loss 81.0593, KL-Loss 3.3062, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 86.0070, NLL-Loss 82.7107, KL-Loss 3.2963, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 94.0666, NLL-Loss 90.9242, KL-Loss 3.1425, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 84.8776, NLL-Loss 81.6064, KL-Loss 3.2713, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 85.1737, NLL-Loss 81.6718, KL-Loss 3.5020, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 82.2554, NLL-Loss 78.7262, KL-Loss 3.5291, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 84.5004, NLL-Loss 81.1888, KL-Loss 3.3116, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 89.2934, NLL-Loss 85.9605, KL-Loss 3.3329, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 83.1897, NLL-Loss 79.8446, KL-Loss 3.3452, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 86.9462, NLL-Loss 83.5995, KL-Loss 3.3467, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 92.2742, NLL-Loss 89.0690, KL-Loss 3.2052, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 94.2635, NLL-Loss 90.8305, KL-Loss 3.4330, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 103.8119, NLL-Loss 100.5459, KL-Loss 3.2660, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 77.3898, NLL-Loss 74.1216, KL-Loss 3.2682, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 83.8988, NLL-Loss 80.6355, KL-Loss 3.2633, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 84.0397, NLL-Loss 80.6819, KL-Loss 3.3578, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 87.4230, NLL-Loss 84.1827, KL-Loss 3.2403, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 85.5386, NLL-Loss 82.3254, KL-Loss 3.2131, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 84.5578, NLL-Loss 81.2819, KL-Loss 3.2759, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 104.4841, NLL-Loss 101.1726, KL-Loss 3.3115, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 80.4645, NLL-Loss 77.0214, KL-Loss 3.4431, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 89.1483, NLL-Loss 85.9463, KL-Loss 3.2020, KL-Weight 1.0000\n",
      "TRAIN Epoch 16/20, ELBO 90.7405, NLL 87.4602, KL 3.2803, PPL 76.4762\n",
      "VALID Epoch 16/20, ELBO 104.9026, NLL 101.6190, KL 3.2835, PPL 160.1293\n",
      "TEST Epoch 16/20, ELBO 102.9814, NLL 99.6673, KL 3.3141, PPL 145.0309\n",
      "Model saved at vamp/E16.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 94.6963, NLL-Loss 91.5890, KL-Loss 3.1073, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 92.2607, NLL-Loss 88.9506, KL-Loss 3.3101, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 86.2873, NLL-Loss 82.8662, KL-Loss 3.4210, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 90.6012, NLL-Loss 87.3715, KL-Loss 3.2296, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 91.4490, NLL-Loss 88.1486, KL-Loss 3.3004, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 86.4717, NLL-Loss 83.4314, KL-Loss 3.0404, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 96.4649, NLL-Loss 93.2277, KL-Loss 3.2373, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 84.5963, NLL-Loss 81.0929, KL-Loss 3.5033, KL-Weight 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Batch 0400/1315, ELBO-Loss 100.5135, NLL-Loss 97.4000, KL-Loss 3.1135, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 95.9178, NLL-Loss 92.4576, KL-Loss 3.4601, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 103.8518, NLL-Loss 100.8077, KL-Loss 3.0441, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 97.3851, NLL-Loss 94.2878, KL-Loss 3.0973, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 86.3554, NLL-Loss 82.8018, KL-Loss 3.5536, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 87.2759, NLL-Loss 83.9148, KL-Loss 3.3611, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 77.2480, NLL-Loss 73.7968, KL-Loss 3.4513, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 90.6391, NLL-Loss 87.1293, KL-Loss 3.5098, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 87.2768, NLL-Loss 84.0073, KL-Loss 3.2695, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 81.7292, NLL-Loss 78.4708, KL-Loss 3.2584, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 73.6613, NLL-Loss 70.1870, KL-Loss 3.4743, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 81.1413, NLL-Loss 77.8051, KL-Loss 3.3362, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 85.4772, NLL-Loss 82.1721, KL-Loss 3.3052, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 94.6701, NLL-Loss 91.4757, KL-Loss 3.1943, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 91.2147, NLL-Loss 87.9163, KL-Loss 3.2985, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 101.7007, NLL-Loss 98.5218, KL-Loss 3.1789, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 84.2236, NLL-Loss 80.7563, KL-Loss 3.4673, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 96.4452, NLL-Loss 93.0785, KL-Loss 3.3666, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 94.2415, NLL-Loss 90.9583, KL-Loss 3.2832, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 89.1289, NLL-Loss 85.9616, KL-Loss 3.1672, KL-Weight 1.0000\n",
      "TRAIN Epoch 17/20, ELBO 90.6277, NLL 87.3484, KL 3.2793, PPL 76.0534\n",
      "VALID Epoch 17/20, ELBO 104.9150, NLL 101.6314, KL 3.2837, PPL 160.2279\n",
      "TEST Epoch 17/20, ELBO 102.9831, NLL 99.6623, KL 3.3207, PPL 144.9950\n",
      "Model saved at vamp/E17.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 88.7351, NLL-Loss 85.6332, KL-Loss 3.1018, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 86.2991, NLL-Loss 82.9901, KL-Loss 3.3090, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 87.2240, NLL-Loss 83.8082, KL-Loss 3.4158, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 98.4122, NLL-Loss 95.3580, KL-Loss 3.0542, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 95.9349, NLL-Loss 92.5671, KL-Loss 3.3678, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 90.3194, NLL-Loss 87.1195, KL-Loss 3.2000, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 88.5127, NLL-Loss 85.3636, KL-Loss 3.1491, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 89.6459, NLL-Loss 86.3354, KL-Loss 3.3105, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 95.8344, NLL-Loss 92.5917, KL-Loss 3.2427, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 94.1327, NLL-Loss 90.7183, KL-Loss 3.4145, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 86.8314, NLL-Loss 83.4614, KL-Loss 3.3699, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 90.8197, NLL-Loss 87.6446, KL-Loss 3.1750, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 89.7392, NLL-Loss 86.4891, KL-Loss 3.2500, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 84.8596, NLL-Loss 81.6419, KL-Loss 3.2177, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 85.0001, NLL-Loss 81.5742, KL-Loss 3.4259, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 84.5921, NLL-Loss 81.1605, KL-Loss 3.4316, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 80.8066, NLL-Loss 77.5187, KL-Loss 3.2879, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 92.3332, NLL-Loss 89.0048, KL-Loss 3.3284, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 90.6536, NLL-Loss 87.4147, KL-Loss 3.2389, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 88.4115, NLL-Loss 85.2861, KL-Loss 3.1255, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 86.7672, NLL-Loss 83.4160, KL-Loss 3.3512, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 86.5062, NLL-Loss 83.2589, KL-Loss 3.2473, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 99.6722, NLL-Loss 96.4358, KL-Loss 3.2365, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 86.4152, NLL-Loss 83.1091, KL-Loss 3.3061, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 81.5061, NLL-Loss 78.0670, KL-Loss 3.4391, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 80.9804, NLL-Loss 77.4508, KL-Loss 3.5296, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 93.5027, NLL-Loss 90.3447, KL-Loss 3.1580, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 96.2350, NLL-Loss 92.9257, KL-Loss 3.3093, KL-Weight 1.0000\n",
      "TRAIN Epoch 18/20, ELBO 90.4679, NLL 87.1892, KL 3.2788, PPL 75.4553\n",
      "VALID Epoch 18/20, ELBO 104.9056, NLL 101.6226, KL 3.2831, PPL 160.1574\n",
      "TEST Epoch 18/20, ELBO 102.9591, NLL 99.6452, KL 3.3139, PPL 144.8709\n",
      "Model saved at vamp/E18.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 92.3521, NLL-Loss 89.0928, KL-Loss 3.2593, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 84.3527, NLL-Loss 81.0196, KL-Loss 3.3331, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 96.2090, NLL-Loss 92.9089, KL-Loss 3.3001, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 97.0967, NLL-Loss 93.9398, KL-Loss 3.1569, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 98.8991, NLL-Loss 95.5385, KL-Loss 3.3606, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 98.8771, NLL-Loss 95.7899, KL-Loss 3.0873, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 98.1589, NLL-Loss 94.8351, KL-Loss 3.3238, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 84.0303, NLL-Loss 80.5285, KL-Loss 3.5019, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 87.9145, NLL-Loss 84.6849, KL-Loss 3.2296, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 91.0000, NLL-Loss 87.7394, KL-Loss 3.2606, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 98.8772, NLL-Loss 95.7999, KL-Loss 3.0773, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 85.8538, NLL-Loss 82.6996, KL-Loss 3.1542, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 85.5313, NLL-Loss 82.1590, KL-Loss 3.3723, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 78.6757, NLL-Loss 75.2222, KL-Loss 3.4534, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 95.1883, NLL-Loss 91.9593, KL-Loss 3.2290, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 97.4025, NLL-Loss 94.1876, KL-Loss 3.2150, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 88.6229, NLL-Loss 85.4830, KL-Loss 3.1400, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 102.6901, NLL-Loss 99.6025, KL-Loss 3.0876, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 91.3911, NLL-Loss 88.0218, KL-Loss 3.3693, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 94.6059, NLL-Loss 91.5075, KL-Loss 3.0985, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 85.7830, NLL-Loss 82.2755, KL-Loss 3.5075, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 78.6629, NLL-Loss 75.2786, KL-Loss 3.3843, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 86.0807, NLL-Loss 82.7507, KL-Loss 3.3300, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 95.0756, NLL-Loss 91.8140, KL-Loss 3.2616, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 90.2748, NLL-Loss 86.9303, KL-Loss 3.3445, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 77.6876, NLL-Loss 74.3506, KL-Loss 3.3371, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 82.4059, NLL-Loss 79.0412, KL-Loss 3.3647, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 75.4917, NLL-Loss 71.9626, KL-Loss 3.5291, KL-Weight 1.0000\n",
      "TRAIN Epoch 19/20, ELBO 90.4410, NLL 87.1624, KL 3.2786, PPL 75.3550\n",
      "VALID Epoch 19/20, ELBO 104.9125, NLL 101.6279, KL 3.2846, PPL 160.2001\n",
      "TEST Epoch 19/20, ELBO 102.9640, NLL 99.6474, KL 3.3166, PPL 144.8865\n",
      "Model saved at vamp/E19.pkl\n",
      "\n",
      "Total cost time 00 hr 33 min 21 sec\n"
     ]
    }
   ],
   "source": [
    "# training setting\n",
    "epoch = 20\n",
    "print_every = 50\n",
    "\n",
    "# training interface\n",
    "step = 0\n",
    "tracker = {'ELBO': [], 'NLL': [], 'KL': [], 'KL_weight': []}\n",
    "start_time = time.time()\n",
    "for ep in range(epoch):\n",
    "    # learning rate decay\n",
    "    if ep >= 10 and ep % 2 == 0:\n",
    "        learning_rate = learning_rate * 0.5\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "\n",
    "    for split in splits:\n",
    "        dataloader = dataloaders[split]\n",
    "        model.train() if split == 'train' else model.eval()\n",
    "        totals = {'ELBO': 0., 'NLL': 0., 'KL': 0., 'words': 0}\n",
    "\n",
    "        for itr, (enc_inputs, dec_inputs, targets, lengths) in enumerate(dataloader):\n",
    "            bsize = enc_inputs.size(0)\n",
    "            enc_inputs = enc_inputs.to(device)\n",
    "            dec_inputs = dec_inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # forward\n",
    "            logp, z_q, mu, logvar = model(enc_inputs, dec_inputs, lengths)\n",
    "\n",
    "            # calculate loss\n",
    "            NLL_loss = NLL(logp, targets, lengths + 1)\n",
    "            # KL loss\n",
    "            log_p_z = log_prior(z_q)\n",
    "            log_q_z = log_Normal_diag(z_q, mu, logvar, dim=1)\n",
    "            KL_loss = torch.sum(-(log_p_z - log_q_z))\n",
    "            KL_weight = linear_anneal(step, len(dataloaders['train']) * 10)\n",
    "            loss = (NLL_loss + KL_weight * KL_loss) / bsize\n",
    "            \n",
    "            # cumulate\n",
    "            totals['ELBO'] += loss.item() * bsize\n",
    "            totals['NLL'] += NLL_loss.item()\n",
    "            totals['KL'] += KL_loss.item()\n",
    "            totals['words'] += torch.sum(lengths).item()\n",
    "\n",
    "            # backward and optimize\n",
    "            if split == 'train':\n",
    "                step += 1\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "                optimizer.step()\n",
    "\n",
    "                # track\n",
    "                tracker['ELBO'].append(loss.item())\n",
    "                tracker['NLL'].append(NLL_loss.item() / bsize)\n",
    "                tracker['KL'].append(KL_loss.item() / bsize)\n",
    "                tracker['KL_weight'].append(KL_weight)\n",
    "\n",
    "                # print statistics\n",
    "                if itr % print_every == 0 or itr + 1 == len(dataloader):\n",
    "                    print(\"%s Batch %04d/%04d, ELBO-Loss %.4f, \"\n",
    "                          \"NLL-Loss %.4f, KL-Loss %.4f, KL-Weight %.4f\"\n",
    "                          % (split.upper(), itr, len(dataloader),\n",
    "                             tracker['ELBO'][-1], tracker['NLL'][-1],\n",
    "                             tracker['KL'][-1], tracker['KL_weight'][-1]))\n",
    "\n",
    "        samples = len(datasets[split])\n",
    "        print(\"%s Epoch %02d/%02d, ELBO %.4f, NLL %.4f, KL %.4f, PPL %.4f\"\n",
    "              % (split.upper(), ep, epoch, totals['ELBO'] / samples,\n",
    "                 totals['NLL'] / samples, totals['KL'] / samples,\n",
    "                 math.exp(totals['NLL'] / totals['words'])))\n",
    "\n",
    "    # save checkpoint\n",
    "    checkpoint_path = os.path.join(save_path, \"E%02d.pkl\" % ep)\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(\"Model saved at %s\\n\" % checkpoint_path)\n",
    "end_time = time.time()\n",
    "print('Total cost time',\n",
    "      time.strftime(\"%H hr %M min %S sec\", time.gmtime(end_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_q.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST Epoch 19/20, ELBO 3992.1922, NLL 199.2930, KL 3792.8991, PPL 144.8805\n"
     ]
    }
   ],
   "source": [
    "# another KL\n",
    "\n",
    "\n",
    "with torch_nograd():\n",
    "    \n",
    "    model.eval()\n",
    "    for itr, (enc_inputs, dec_inputs, targets, lengths) in enumerate(dataloaders['test']):\n",
    "        bsize = enc_inputs.size(0)\n",
    "        enc_inputs = enc_inputs.to(device)\n",
    "        dec_inputs = dec_inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "\n",
    "        # forward\n",
    "        logp, z_q, mu, logvar = model(enc_inputs, dec_inputs, lengths)\n",
    "\n",
    "        # calculate loss\n",
    "        NLL_loss = NLL(logp, targets, lengths + 1)\n",
    "        # KL loss\n",
    "        log_p_z = log_Normal_standard(z_q, dim=1)\n",
    "        log_q_z = log_Normal_diag(z_q, mu, logvar, dim=1)\n",
    "        KL_loss = torch.sum(-(log_p_z - log_q_z))\n",
    "        #KL_weight = linear_anneal(step, len(dataloaders['train']) * 10)\n",
    "        KL_weight = 1\n",
    "        loss = (NLL_loss + KL_weight * KL_loss) / bsize\n",
    "\n",
    "        # cumulate\n",
    "        totals['ELBO'] += loss.item() * bsize\n",
    "        totals['NLL'] += NLL_loss.item()\n",
    "        totals['KL'] += KL_loss.item()\n",
    "        totals['words'] += torch.sum(lengths).item()\n",
    "    samples = len(datasets['test'])\n",
    "    print(\"%s Epoch %02d/%02d, ELBO %.4f, NLL %.4f, KL %.4f, PPL %.4f\"\n",
    "          % (split.upper(), ep, epoch, totals['ELBO'] / samples,\n",
    "             totals['NLL'] / samples, totals['KL'] / samples,\n",
    "             math.exp(totals['NLL'] / totals['words'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "tensor([ 184.5047,    0.8758,    3.9012,   11.9410,   36.5258,   96.2879,\n",
      "          14.3265,    0.2849,   13.5582,    0.0846,  324.0168,    0.0563,\n",
      "         526.7479,   14.3680,   99.3105,    1.5736], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# calculate au\n",
    "\n",
    "delta = 0.01\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    cnt = 0\n",
    "    for itr, (enc_inputs, dec_inputs, targets, lengths) in enumerate(dataloaders['test']):\n",
    "        bsize = enc_inputs.size(0)\n",
    "        enc_inputs = enc_inputs.to(device)\n",
    "        dec_inputs = dec_inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "\n",
    "        # forward\n",
    "        logp, z, mu, logvar = model(enc_inputs, dec_inputs, lengths)\n",
    "        \n",
    "        if cnt == 0:\n",
    "            mu_sum = mu.sum(dim=0, keepdim=True)\n",
    "        else:\n",
    "            mu_sum = mu_sum + mu.sum(dim=0, keepdim=True)\n",
    "        cnt += mu.size(0)\n",
    "        \n",
    "    mu_mean = mu_sum / cnt\n",
    "        \n",
    "    cnt = 0\n",
    "    for itr, (enc_inputs, dec_inputs, targets, lengths) in enumerate(dataloaders['test']):\n",
    "        bsize = enc_inputs.size(0)\n",
    "        enc_inputs = enc_inputs.to(device)\n",
    "        dec_inputs = dec_inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        lengths = lengths.to(device)\n",
    "\n",
    "        # forward\n",
    "        logp, z, mu, logvar = model(enc_inputs, dec_inputs, lengths)\n",
    "        \n",
    "        if cnt == 0:\n",
    "            var_sum = ((mu - mu_mean) ** 2).sum(dim=0)\n",
    "        else:\n",
    "            var_sum = var_sum + ((mu - mu_mean) ** 2).sum(dim=0)\n",
    "        cnt += mu.size(0)\n",
    "        \n",
    "    au_var = var_sum / (cnt - 1)\n",
    "    \n",
    "    print((au_var >= delta).sum().item())\n",
    "    print(au_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 184.5692,    0.9213,    3.9346,   11.9463,   36.5503,   96.1669,\n",
      "          14.3048,    0.3955,   13.6000,    0.1709,  324.1462,    0.0876,\n",
      "         526.3391,   14.3280,   99.3167,    1.6628], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(au_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaMAAAEhCAYAAADS7c8nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nI2OMMb77f9Ayz8FlI4CmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe338fe1048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot KL curve\n",
    "fig, ax1 = plt.subplots()\n",
    "lns1 = ax1.plot(tracker['KL_weight'], 'b', label='KL term weight')\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.set_xlabel('Step')\n",
    "ax1.set_ylabel('KL term weight')\n",
    "ax2 = ax1.twinx()\n",
    "lns2 = ax2.plot(tracker['KL'], 'r', label='KL term value')\n",
    "ax2.set_ylabel('KL term value')\n",
    "lns = lns1 + lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax1.legend(lns, labs, bbox_to_anchor=(0., 1.02, 1., .102),\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent space visualization\n",
    "features = np.empty([len(datasets['test']), latent_dim])\n",
    "gz = np.empty([len(datasets['test']), latent_dim])\n",
    "for itr, (enc_inputs, dec_inputs, _, lengths) in enumerate(dataloaders['test']):\n",
    "    enc_inputs = enc_inputs.to(device)\n",
    "    dec_inputs = dec_inputs.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    _, z, mu, _ = model(enc_inputs, dec_inputs, lengths)\n",
    "    start, end = batch_size * itr, batch_size * (itr + 1)\n",
    "    features[start:end] = mu.data.cpu().numpy()\n",
    "    start, end = batch_size * itr, batch_size * (itr + 1)\n",
    "    gz[start:end] = z.data.cpu().numpy()\n",
    "    \n",
    "tsne_z = TSNE(n_components=2).fit_transform(features)\n",
    "tracker['z'] = tsne_z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzsvXl4XGd59/95zqySRrtGsmTZkiPH\njh3HcZzEZKGQxCQlhCwNbSDQErrl7Y/SQNrSFNoGmhcKKRRIoKH4pUBowQmQHUhw7ESExHYUW7bj\nRZassSRb64z22Zdznt8fo1G0rzPSSHo+1+VLnjNnznk0mvme59zPfX9vIaVEoVAoFMsfbbEHoFAo\nFIqFQQm+QqFQrBCU4CsUCsUKQQm+QqFQrBCU4CsUCsUKQQm+QqFQrBCU4CsUCsUKQQm+QqFQrBCU\n4CsUCsUKwbzYAxhJUVGRrKysXOxhKBQKxZLi8OHD3VJK53T7pZXgV1ZWcujQocUehkKhUCwphBAt\nM9lPhXQUCoVihaAEX6FQKFYISRF8IcT9QoiTQogTQojdQgi7EGKdEOJNIUSjEOJJIYQ1GedSKBQK\nxdyYt+ALIVYD9wFXSCm3ACbgI8DDwDellOuBPuDP53suhUKhUMydZIV0zECGEMIMZAIdwA3AL4ae\nfxy4I0nnUigUCsUcmLfgSynbgK8D54gL/QBwGOiXUsaGdmsFVk/0eiHEvUKIQ0KIQx6PZ77DUSgU\nCsUkJCOkkw/cDqwDyoAs4P0zfb2UcpeU8gop5RVO57RppApF0nB5fOyr68Ll8S32UBSKBSEZefjv\nA5qklB4AIcTTwLVAnhDCPDTLLwfaknAuhWLOVNe7qW3pY3tFPmsKMvn7nx3D4w3hzLbz9bsupcrp\nWOwhKhQpJRmCfw64SgiRCQSBncAh4FXgD4EngHuA55JwLoViTlTXu3nwuZNoQvLs0XbyMsy83TaI\nSUD7QIjP7D7C3/3+Rq7bWLzYQ1UoUkYyYvhvEl+crQWODx1zF/AA8LdCiEagEPjv+Z5LoZgIl8fH\n/x5s4ScHWyYNz9S29KEJSUlOBr5wlONtgwDoEgwJpzoG+ezPj7G7ZkYFiwrFkiQp1gpSyi8AXxiz\n+SywIxnHVygmw+Xx8fCLp9l7qgsDsGjw0v3vHRee2V6Rz7NH22nq9tHnjyLHHEeXMBCM8p1XzlCa\nm6Fm+opliaq0VSxpmrv9vHo6LvYAUQNuffS1cfutKcjkuo1F6IbEPMmnPqJLfKEYD71win959jjV\n9e7UDVyhWASU4CuWNJVFWUSN0dsCUTkqNOPy+Hjs1UZePe2h1x8dt/9IBkI6Z7v9PFPbxoPPnVSi\nr1hWpJVbpkIxW6qcDgqyLPT6o6O2/2h/M6W5GeiG5LcNbt44002nNzzj4wYiOpnRGLUtfSq8o1g2\nKMFXLHlq/+UmLv3X3zAQjNf55drNZFnNfO81FyYheLOpl6g+Nmo/NQYQiuhsr8hPwYgVisVBhXQU\ny4JjX/h9vnLnFjaucnBJeS52s0au3cL53sCsxR7ihlBXVBaypiAz+YNVKBYJNcNXLBvu3lHBjnWF\nNHf7MWmCR/ed4VxvcE7HMoAT7f08/GIdD9y8SRVlKZYFaoavWFZUOR3s3FRCx0CQuo6BcemXM0UC\nA6Eo3d4wzd3+ZA5RoVg0lOArlh0uj4/H97cQm0MoZySGLjGIZwIpFMsBJfiKZUdzt58ihxWr2YSY\n4zEyLRrrnQ4+874NKpyjWDaoGL5i2VFZlEVJjp3L1ubR1h9iVbaNjoEg5/qCIGGKNHwACrMs/MlV\nldy6rUyJvWJZoQRfseyocjr45PXrae72U1mUNSzaX3z+BD976zwmTRCKGoBEN0ATgACLSaM0N4MH\nb92scu8VyxIl+IplSZXTMW52nmO3UJxjoyQng/N9ATYUO7hx8yquqioEGHeBUCiWG0rwFSuGhIFa\n12AQs6bxiWvXjZrJK6FXLHeU4CtWDNdtLOah2xlugqLCNoqVhhJ8xYriuo3FSugVK5akpGUKIfKE\nEL8QQpwWQtQJIa4WQhQIIV4WQpwZ+qlMSRQKhWIRSVYe/iPAS1LKi4BLgTrgH4F9UsoLgX1DjxUK\nhUKxSMxb8IUQucB7GGphKKWMSCn7gduBx4d2exy4Y77nUigUCsXcScYMfx3gAX4ohDgihPi+ECIL\nKJFSdgzt0wmUJOFcCsWyoLrezTf21KsGK4oFJRmLtmZgO/A3Uso3hRCPMCZ8I6WUQogJjU2EEPcC\n9wKsXbs2CcNRKNKb6no3n/35MXzhGMZr8P4tJdy3U1k4KFJPMgS/FWiVUr459PgXxAW/SwhRKqXs\nEEKUAhNOZaSUu4BdAFdcccX83K4UijTG5fHR3O3nkb1n8Pgiw9tfONpBtzfCX77nAnRDquIvRcqY\nt+BLKTuFEOeFEBullPXATuDU0L97gK8O/XxuvudSKJYSLo+Pg64ePN4QTT1+DjX3E4nG8Ixpx2gA\nLrePr7xYx7rCLI6d78cfjrLjgiK+f8+VizN4xbIkWXn4fwP8RAhhBc4Cf0p8feBnQog/B1qAu5J0\nLoUi7XF5fDz8Yh0n2gbp8YWJ6HJKb/5ufwQDg3M9AYJDXdb31rm5e9cBdt979cIMegQuj48Drh4E\ncFVVobrjWCYkRfCllEeBKyZ4amcyjq9QLDWau/14vBEiUR1DTi32ACaTQKARjI6e/b/V1IvL41sw\nwa2ud7OvrovDLX10DIQQwKbSbB664xKqnA6q693DlcprCjKHu4upUNTSQFXaKhQpwKQJOgeDeCMx\notP5MQORqIHFIbAIiI64OjizbTR3+xdESHfXtPAfexqIxgwGQ7Hhi9Shpl4+/9TbBKMGjW4vDruZ\nnx9u5YKiTFweP12DYVbl2LhmfRGfvH69Ev00Rgm+QpECXjndRTCiYxgzy0OQQGd/iNK8DELRGB5f\nFGeWhWvWFy1Ix61El7BgRCcY1UfdkYQNeLO5753HsQhWs8bRc2H8Q1enjsEw+xu7+cAlpUrw0xgl\n+IoFY2Q44LqNxeyuaWF/Yw/XrC/k7h0VQHyW+ZsTnawtyOKeayuXpHjsrmnhybfOE47NLuksJqG1\nL8htl5byB9vLFzRMkugS1uTxMd01SpcMrzOMpHMwjEmba48xxUKgBF+xIFTXu3nwuZNoQrK75hyl\neXbqOgZBwksnOjjo6qWqOIvHql1EYwaIHo639fP1u7YtOdHf39gz45n9RHT0hxbc4C3RJcxq1gjr\n+pyOUZJjQ5/H761IPaqnrWJBqG3pQxMSq8lEbyDK262DRHWIGvF/zx1r5z9fOUM0ZmDSBAJJXccg\nf/jYG9z/5JHFHv6suLDEwXz6p797Q1HyBjNDEl3Cdm6a3YXGaor/XJVj49oFCj8p5o4SfMWCsL0i\nH0MKugYCk84Cw3o8XBDRJTEDQjFJXzDGM0fal5ToX1yWy7Y1eZTl2jDN4nUCWJOfwS1by1I1tCmp\ncjr41ke2c+nqnBm/RhOCzaXZ3HXFGrVguwRQgq9YEOLNRy7mvRtLMM8hzrvnROeS8Z2pLMpiXVEW\n64oc5GaaZ/Ul6/VHeOFoW8rGNhO+8ZHLuGxNHoWZFszTDD4Uk7g8fkrz7ErslwBK8BULxnUbi7nz\n8nIumMNtf1RKHnzu5JIQ/UR4pMrpIDBmcdM6xTdOAhHdoLrBg8vjS+0gp6DK6eDrd13Kn1xdgUlM\nfXHWgNwMMx39oYUZnGJeKMFXLBiJhduIruOwmWb14dOAgUCYp2pbUzW8pFLldJCXaUEjbp2QYLo1\nzeJsO6ty7DR3+1M5vGmpcjq4pDyP8vxMppJ8kwnsFjPbK1R/o6WAEnzFgpFYuC3JyaDIYeXKynxM\nM4zuhGKSwZDOQVfPkpjlQ3zdIjxmhm9IcFjH/9JmAeV5GWxZnUOWzZwWi5+VRVlUFTvIz5w4mc+s\nwburnDx0+8WqbeQSQaVlKhaM7RX5PHu0na7BIIYUXFVVhDcc43SHlxkUo2LWBBazRm1L35IQmOs2\nFnP9pmL21r1zgcqwmti5qZiXTnYQjsW3CWBNQSZfuO3itLIoqHI6eODmizjg6qGh08vrjd0IJAjB\n2vxMbtpSMlw/oVgaKMFXLBjxhVtGebG81dSD3aKNi3VPhKZBNGYsqfDB9++5ki8+f4LfnOzA6bDz\ntzdtZE1BJud6g5zqGAQkmVYz9773grS8iFU5HcMXn4S9c7pckBSzR0iZPoUSV1xxhTx06NBiD0Ox\ngFTXu/nnZ07Q2h+cdB8NKM6xkZtp4RPXVC6LWaXL4+OFo+10+8O8b1NJWoq9YukghDgspZzIwHL0\nfkrwFYtNdb2bz+w+Qn8oNrxNAywmQXlBJqty7HzgklJl06tQTMJMBV+FdBSLznUbi3ngAxfx7y/V\nYxhxK+E7LivjhotK0iqmrVAsdZTgK9KCu3dUUJqbMcpcTaFQJJekCb4QwgQcAtqklB8UQqwDngAK\ngcPAn0gpI1MdQ7GyuW5jsRJ6hSKFJHOG/2mgDkgYcTwMfFNK+YQQ4r+APwe+m8TzKYBrv7qPtv4Q\nDqvGdz52+awEs7rezTf31OPxhdlclsvm0hw1u1YoljFJKbwSQpQDtwDfH3osgBuAXwzt8jhwRzLO\npXiHhNgD+CIGn/jhW3x695FxZfnV9W6+sad+VMHSo/sa+MvH3+JY2yDtA2H21rn54RtNS8a+QKFQ\nzJ5kzfC/BfwDkD30uBDol1Im0i5agdUTvVAIcS9wL8DatWuTNJyVQdsE/iW/fLudbl9oVA/ShA/9\ns0fbueEiN6faB3m7tX9c671wTEcTcskUNikUitkx7xm+EOKDgFtKeXgur5dS7pJSXiGlvMLpdM53\nOCuK1Xn2Cbd3DIR47kgbLo9vlJ3BQDDC4/tbqGnuIzRBNybdgPASK2xSKBQzJxkz/GuB24QQHwDs\nxGP4jwB5Qgjz0Cy/HFhcz9dlyBv/uJPt/3cPvf7o8DZNA28oxhuN3bzwdgcl2Vb6/FF6vBF8kdG9\nSkeSm2Emx2amdJKLiEKhWPoktfBKCHEd8PdDWTo/B54asWj7tpTysalerwqv5kZ1vZunDrfiGypc\nOtcboGMgSChmYEjGOTZOhEUDoQkcVjMxQ/IXv7eO+3ZuSPnYFQrF/EmHwqsHgCeEEF8CjgD/ncJz\nrWgS6Ywuj48Hnz1Ox0BwlDfNTIzJogZoUjIQjN8tfP+1s2wtz1t2sXyXx8dBVw9ub5i+QBhpwM7N\nytpAsTJIquBLKauB6qH/nwV2JPP4iqk56OqhrtMbbwI+BxJe7ZoA8xJypZwp1fVuHnrhFK29/uEF\na6tZ47lj7dxwkZMcuwUp1QVAsXxRlbbLiJrmHvr80Unj9DNFACYhltzi7f1PHqG63o0z28bnP7B5\nWLRdHh8HXD384PWzNHUHRr0/4ZhBJGbwwrEOIH4B2HvazVfuvGRFiX7izqemuYezbj/ObBsfv6Zy\nRb0HKwEl+MuIJrcfSXyGPl1npamwmQV/e9OGJfVlv//JIzxzpB2AvkCMv3j8EJ+6fj3b1ubxwrF2\nznr8tPYFJ7wYSiCxlGXWBLquL7u7m6lIhALfau4jor/zDr3Z1Mv/ee8FFGTZEKDM65YBSvCXCdX1\nbs4PWQzPVuwT/Zc0ERe/GzeXLjkL4oOunlGPY4bkiZoWapp60DRBx0BwlJiNJREEC0R0zCZtyd3d\nzIeDrh6One8f9/74IzrfrW4kw2LCbjHz2wY3D9y8iSqnY9gb/2T7AGe6fFyzvnDJfWZWIkrwlwm1\nLX3kZpjJtJhoG5hdQ2mzBvlZVqwmgTPbzn3vuzBFo0wdV1UVDs/wE2iaQNMEpzu89PpnZuM0w46L\nywoJRPWJ132CUUkwGkMjhjcU4TO7j3DjxSW09AR4o7GbzsEwJgGvnI5XZyvRT29UT9tlwvaKfAwp\niBoGFi3uJT8TLCZwZFj46I4K/vX2S/j6XduW5G37Nz98GdvKc4cfJ9Yh6ju9BCKxGWUqAdgsGpGY\nwb66rpSMMx25uqqQC5zZU+5jAN6wwfH2Qb7zSuOw2APoEiK6zv7GnimPoVh81Ax/mZBoH7ivrosT\nbYO09PpHFWSNJS/DjNWkIZFsKMnh1m1lS1LoR/Lsp97N7poWfnOik67BMAiJfyCM2aQxzkdiEnQp\nEUBBli21g52ChW4lWOV08J2PbefWR18jEJ0+HhjT5bDYv7MNrllfmKohKpKEEvxlxMh8/B+93sSr\nDV34Qjr+iD7cWGRNfiYxQ+eGi0q4aFUOkvgMb6mLfYLS3AwEAl84ijFUVzBF6H4cGpBlM3PZ2ryU\njXEsiSyit5p66egPEjUkWTYTHl94wVo6VjkdOLPttPRO3moywUSXzp2bilU4ZwmgBH8ZUuV08Il3\nr6PLG6K+00emVcduMeMNRRBCYtJM7FyGfVSr69187unj9PjCUy7QToVAY+OqbPT5pDlNQnW9e1SD\nF5fHx/NH29lzspOWHv+oYjmLCawmE9/Y00BpbkbK/1bV9e45r19YTfC5D2xK6ngUqUEJ/jKlyung\ngZs3cdDVMzyLP98bWNYdpWpb+tB1HZMmmNW0fgQxI343VFmUldSxTeRa+lpDNz2+EIGIPi7iFNUh\npuvohs7Tta0p/XslxuYeE6aZKRlWMwddPcvmLnE5owR/GVPldIz6ElY5HctS6BNsr8jn54dbMWRs\n+p0noSw/k3vfW5U08aqud/P04VZOdw4SisZYV+TgjNvLj/e3DIdGJptZSyAUg+p6D9X17pT97RKO\nqjkZZkLe2TWly7Ro5GVY5l3sp1gYlOArlg3XbSzmK3dewr5TXTR0+TjU0jurif4NG5380wc3J1Xs\nP/vzY/T4I0gZF/B+fy+RMbP56YYYS3Eh2PaKfJ492k54hgvbIzGkpDw/k6ur1ILtUkAJvmJZMXLh\n+lM/qaWu0zv8nNUkkEjMmkY4amAyCSoKMjGbNO65piLpi461LX14Q7FRhXBjxX4mhGIS8wzTbOdC\nIsPry788xWAoNuUFyAToJNJeochh4wOXlKZdOGeyTKex6ygrDSX4imVJItXw0b1nONUxwNqCTFbn\nZfJyXSeagHBM8vGrK7i4LDdl6Y/n+wKE5mhkZxmqkMm2WzCbBLGhW5VUpWxet7GYjoEgX3j+JNFY\nPKPLrAnsZg1fRMduFqwryuLj11Tys7dacbkHsVvMbC7L4apFnt2PfU/iVhEn6PVHKMiy8tAdW0Z1\nf4sZBrtrzvG3N22gpqmXg64erqoq5JsfvmxRf4+FIKl++PNF+eErUs1CzfCq69188n8Pj8q8mSkC\nKM/PIBjVcdhMGFJgEtDUEwBgvTOLS9fk8cnr1yf9QrW7poVnalsRaJhNgrK8DAaCUd67wTnspZNI\nI00Hf53qejcPv1iHNxQj227mgZs38eyRVl441oGmxT2Sfm+9k3++dTPPHWnjibfOEYzoxAyJSQh8\nEX34WH9wWdmSFf2Z+uErwVcoUsA39tTzX79tZISezJhMq4mNJdnkZVjIzjBzvHVgWOwTrHdm8bkP\nbGLnppIkjXg8C10ANlsSYbv6Ti9SxGsonNk2PN7wqLWbTIvGuy8sYsvqXP7zVRcx3UATguiY1Fuz\ngMav3LKwv0SSWLAGKEKINcCPgRLi60+7pJSPCCEKgCeBSqAZuEtK2Tff8ykUSwGzSTDHaA6XlOVw\nri9AXyCMIQXtvYFx+3QOBJOeOjqWsVle6YTL4+OHbzTh9oaH3U51oGswPG4NImYYeLwRYrpkS1kO\nzT1+TJrAPSYjaYI2z8uOZMTwY8DfSSlrhRDZwGEhxMvAJ4B9UsqvCiH+EfhH4l2wFMuUR/c1sOdk\nJ1XObO5734VpKxYLQUyXZNvN+EKxWWUK5WaYybCasJk1SnIy6BoMUpBtHSdON168asW9v4lwnNkk\nePF4J+39QXzh0YvME73VER1Otg9QkGUhENEpybFjM5vo9kZGVQ1bVoCz2LwFX0rZAXQM/d8rhKgD\nVgO3A9cN7fY48U5YSvCXKY/ua+Bbe89gSDjR7uX1Rg9///sb2bGuMK3DAqkiUROQ6DM8E0pyrFxa\nnkdZXga15/oJROIV0v/+h5fyrZcbONo6gFWDj15VwRdv25LC0acfiQXXUDSKxxtFDCUtzbQgOqJL\nXj3twWIWZFlNbCrN5YZNxeytcw/v88FLy1Iw8vQiqVk6QohK4DLgTaBk6GIA0Ek85KNYZiRmXU/U\ntIz68vX4o/zr86fIzbBwYYmDkhx7ShYZ05VETcCXf3mKpm4/mhBEplCnqqJMbtlaRmmene9Wn8Vu\nEQQjOn98VcVwqulKpralD93QGQjGRjWsmQ0GIBBk2cwg4O4da8m2m1dUlk7SBF8I4QCeAj4jpRwU\n4p28YSmlFEJM+CcSQtwL3Auwdu3aZA1HkWKq6908VdvKQVcPFrOG2zfemTMUMwh5w7i9Ycrz7Gxf\nm79iBB8YFunPPf024aiBPxIjP9NCjy8CIm6fYNbAYtLIybBy+2Wree5IG5qQrCvKpmswOJyOudLZ\nXpHP//vdWcLzDLTrUqIbkiyrmcqirBUh8iNJiuALISzExf4nUsqnhzZ3CSFKpZQdQohSwD3Ra6WU\nu4BdEM/SScZ4FMlnd00L+xt7uGZ9IaW5GXzu6eP0+kOEY3HRmgoJnO8P8YvDrYuexrfQxGf6W6lt\n6aM0z05xth23N8TJ9kFOtg0QT8KUfHpozSNR9do1GMSQS6+vcCqJzHUVfAgN2L4mj1u3rV5WDrGz\nIRlZOgL4b6BOSvmNEU89D9wDfHXo53PzPVc6M1F+98i0Noi3kqvvGqTfH+UCZxa3blu9JD50u2ta\nePC5E+g6vHSyg+1r8occKePPz/R72O0L0dztXxK/czKZLCQzUdpjoup1JVeDTsQ39jTM1Q8PiFdZ\n52VauG3baj521cq1cU7GDP9a4E+A40KIo0PbPk9c6H8mhPhzoAW4KwnnSksStrzhqM7/HGzhH94f\nX6x87NVG/OEYXYNhun1hOgeCRI34nE4TsOdUF9/+6Pa0F8CfvtlCdEjcDR1Oto3vfzoT2vtD/O6M\nJ6W540uJydIeVcx+NLtrWjjRPjDn11s0QXlBBuudjkWvCl5skpGl8zqTG/7tnO/x05FH9zXwwrF2\nMqwmbthYwlmPj/5AhJghiemSL//yFDs3ldDQ5aPXH8Ybio7qJCSJu/c2dHl54Wgbn7lx4+L9MjNB\njv7zBuYYR9Ul7K45z8ZV2apZhmLG7G/swWISc4rfC2BtYSa3XFLK7ZctjTvqVLICMk+Ty/1PHuEb\nL5/hjNvP262D/Gd1I7Xn+ojqkqge9yDxRQyeO9bB6U4vXd4IwUnaxmlCxBfw0pyPXrUWqyle3m8S\ncX+VuWAza2gC1ftUMSuuWV+IWdNI+MfNxkbObIIcu1mJ/RDKPG0WVNe7efZI+6htUV2CkExU8iHH\n/ByL3WJi5+b0D28kZuP7G3vweEMcbplbwbQm4he5VPQ+Tfi7NHR6MZC8bxl29FqpJD5/e0500eUN\nEY4atPQGiA2luZq1+OcqpkuExvAXLj/Lypr8zOEFcYUS/FlR29I3lFMxBinQZ5lAYBZwx7ayJSNK\nd++oYMe6Qv7+yaPT7zwBW8tzqCjI4pr1hUkN5+yuaeGZw224un34wjEiMYlZg9+c6ORrf3Tpknl/\nFVNz9464fXViodvtDbHnRBdvNfeiS4kmBBeXZfPeDU6Ksm2U52egD3UuU2L/DkrwZ8H2inxyM830\nBd6pnrxhYzFNHt+sO/4UOqzcc+265A4wxTR3+ynJtXOuL0CPf3ze/WSYBNywsYTP3LghaWOprnfz\n3VcbqWnuG/fe6wYMhmLsO9WlBH+ZMXKh++4dFVTXu9lb10VRlo1bt5UpcZ8GJfiz4LqNxXzzw5fx\n4/3N+EIx/uDy1dR3enmlfsISgykJRw1qmpZWH9DKoiyybGZyMywMBqPoBszkxqY0186t25JXtr67\npoV/f6mevsDEFx0DMAwjfnuvWNaojKbZoQR/loz8gFXXu/nX50/N6Thh3eA/9jRQmpuxZD6wVU4H\nn7x+PS8cbefJQ+cJR3W8oRggh5twC8BqFhgGmDQoy8vkwVuT1zbQ5fHx+BvN+EJT32FkWs10DoRw\neXxL6qKqUKQSJfjzoLalD4smCI3YZjNBeBoPdIsJsmxmbGaR0l6lqaDK6eAzN25g29o89tZ10eTx\nIYTgZPsgpbl28jOtXFmZDwiKsm1JrWh0eXw88nIDfYEo0/cVkXT7Iiuy0Gs+PLqvgacOnycYMSjJ\ntfPRd61VKbTLCCX48yDuiHiesG4MLxD9ywc38xc/emtCb22zJriiIo9Gjx+bWWDSTEu2dH5k79jm\n7ri/eCoXyRJt62rP9c2obeBASOfo+X5Otg+oQq8Z8ui+Br758pnhNRG3L8KDz50EUKK/TFCCPw8S\nPin76rooyLJx29Ci0S2XlvLc0Y7h/exmQbbdzIaSHB66YwvnewPLpnR+oZpkNHf76fVHMGti5k6J\nEs50+ZI6jvufPMLrZzxUOR18+c6tw7/7SK+hpSqOe052jl8A1yXP1LbR0R9aFp/XlY4S/Hky0aLR\nfTs3cKbLh3sgRG6WlVu3lo0Kb1Q5HeqLM0sqi7IoyLLi8sxcwM2m5Ob83//kEZ4ZqsPw+Pr4xA9q\n+NGf7aCmqYcv/bIOgFdOu6nv9JJjtywpgXR5fOgT2DcbwMn2QZp74h2mPnR5Ob93oVOlOy5RVE/b\nFJHu/UCXIi6Pj8f3N/HrtzvoniIttCDTzOr8DD76roqkzrav/re9dAyGhx/bzILHPnY5zx5p48Xj\nHRgyXqNh0SAv04LJZOIrd16S9qLv8vh4ZG8DR8714R4MTbsGVZRlYXtFAQ/cfJH6bKcJC9bTVjEx\n6dwPdKlS5XTw0O2XcM8167j/iVrebvOOet5uFmRYzfzdTRtT4oh4VVXh8AwfoDjbjkkTNHQOjlqz\niRgQjBoYEYOnD7emdQFQfG3kOIda+gnP0Pa02x/lzbPdHHAtrbRihRJ8xRKkyungmx/ZzoPPHqdj\nIERfIIpFA4lgQ0nqHBG/+eHL8IZiHHB143TYuPPych5+sY4zbv+4fb1hHZOAE+0D2CwmBoJR3rvB\nmXb9AB5/o5kj53oJz7wTIwBeCrFmAAAgAElEQVSBiD4rTxtFeqAEX7EkqXI6eOiOS4YzhFr7gghI\nqaC6PD40IShy2AhEdR57tZHwkGHeRBgS+oNRzvcFONU+QKPHy6/ebufe91alRZhnd00LPzt8nmlK\nGiakIMu64q2GZ0qiV0aiAY5JE7T1BZHAr95u53THIJdXFvD9e65M+ViU4C9jlvs6QqrCZo/ua+D1\nhm7evaGI+3a+YwdxwNXD+d4AhgRvKEY4NrnYQzyePxCI8lZTL4YEfziALxTje6+5WFOQueh/k/2N\nPXH3U4tGaPrChlH0BaL86u32Ue+PYjzV9W4++/Nj+MIxwjEDi0kQ1eWwTXEiFLi3zs1fPP5WykVf\nCf4yIzGbMJsEzxxpIxCOUZaXwdfv2rboArMUeHRfA4/sawQpOXy+H4hnXbk8Pl5rcNPjC+PxRWbs\nnaTLePWxGPq/P6xjEiItCsKuWV/IK6fdROfQOjCiS7697wzObNuSTUNdCJ463EqvPzLcrSvh6T/R\nO364uTfl40m54Ash3g88ApiA70spv5rqc65UEp23BgIRAiNmbB5fhEf3nuG2bWXLdrafLPac7EQa\nErvVRDiq83pDN/ft3EBzt59ARCcYM2ZllGcWIITApAlCMQMh4FxvEJO2+BHwhFA/U9vG6U4vwXCM\nqIyPeSa9RmIG/Gh/MzvWpde6RDohRDy0NxNyMywptwJJqb2UEMIE/CdwM7AZuFsIsTmV51yJuDw+\n9tV18XRtKz2+8Cixh/gH7pXTXfzwjSb++dnjVM/B7G0l4PL46BgIYRBflJTAuzcUAWDSBKc7vfhD\ns1zdFAKLSWCzQK7dzJWVBWwuzZ4w530xuHtHBT/7q2t49O7LeP/WUpwOK8W5duxmDZsWTz1NXJrM\nY65RNouG02GjuXv8orUizp3by7GNfeMmodMb5sFnj8+q1mS2pHqGvwNolFKeBRBCPAHcDszNcUwx\nDpfHx8Mv1nGqfZCuwdCkHjPesM7Bsz1YTRoPv1iXFjHkdOPRvWfoHZHfv97pYGt5Ht/YU48mBGsL\nMhkIRDBmEQERxDuhFWTZ0aXEZtbIspmHG9unC4kCwpEhwd015xkMRtEsktK8DG7bWoamwcunOnEP\nRriwxEFJjn1Rf5fEeNO1yO26jcV88vr1fOeVxmn7QIeiBnUdXg6mMN011YK/Gjg/4nEr8K5UnnC5\nL1SO5fmj7VTXe2bUVDxmQMwwONvt54Wj7Un1p18OuDxeJPEOSjEDwjGdB587iSYk/rBOzJAzMG0b\njS7BahLkZ1rJzbSwoSR7VLu9dLNkGFk5vrU8j32nuih0WLl12ztjTqxpLPb3rLrePfz3efZoOw/d\nTlqK/n07N+DMtrHrtbN0e8N4J6lsE8TbR6fy3m/RF22FEPcC9wKsXbt2zsdxeXw8f7SdPSc7sVtM\nOLNty74S0OXx8fyxthmJ/UiiMcn+xm7VMGIMN128ilMdXgwj3o5xVY6dLm+InAwrfX4/0dm2NQOQ\ncdHvCUQYCMW4ZWvpcAhkrCUDpJdJ2VRe84tdWOjy+HjslUb6fGEybCYGAlH+4zf1aXvnmugYd8DV\nww9eP0tzd2DUwq0mwGEzs3lVDlenMN011YLfBqwZ8bh8aNswUspdwC6IWyvM5SQuj497/ruG1v7g\n8DaH1bRsKgEf3dfAD99oIhTV2Vqez7/deQlVTgfN3f45ZVgYQH2Xl4dfPL0oF0WXx8cn/+cQ53r9\nbFtbwO57r17Q80/GfTs30NTt53dD5mh3XLaaR/c14nL7iOrGrC+sGvEvss0kuKgkm/5glMf3t1BZ\nmIk3FKPJ4yMc08nJsOANRfnJwRa1ADoFLo+Pf/vVKY639uMNxQgOrSx7I/EZ88mOQf7+Z0eHM9LS\n4S5kJImL5NVVhbxwtJ1jrX0IKSgvzKAg05Z0O/GJSLXgvwVcKIRYR1zoPwJ8NNkn+fzTx0eJPYAv\novPj/U3DPWhT/Uamirt3HeDA2XfStd5s6uVDj73BbdvKGAhE8c6lagbwhWO09gUWPD3Q5fHx4f/a\nP+yFc+BsL3fvOpAWol9d7+bg2V6CEYMTbYOYNcGOygIOnu0mEIaIPo3JzBAa8YuqSQOzyYTVrNEX\njHK+N4DVrHH0fD89vjAxI/7ZTKwbnO7w8qmf1PKdj22nyumgut49zol1peLy+Lj3x4dweaZeIPZ4\nQ8N3UI+92shLJzrwRwxW59l54x93LsRQpyXRU2IxSKngSyljQohPAb8hnpb5AynlyWSew+XxUTtJ\n/mqD288Xnz9BfqaF1xqWntnTo/saRol9gv5gjJ++eS5uEzzHgJ8u44tEC7Hg5vL4OODqodsbptsf\nHtcP9+2hfPfFXoCrbelDNwwyrCaiukHHQIhAxMAAgtGZib0g7tIZ0ePxfkPqVBZmcHFZDllWE+0D\nIc71+Jnoxiwm4XSnl0f3NvAH28v53NNvMxiMZwUdau7loTu2LKnPbzJp7vbT3h+Ych9DQjBi4PbG\nWxIlxB6grT/E9V97lVc/e33Kx5rOpDyGL6X8NfDrVB3/oKuH4Wn8BESNuNlTa+/Cz2bny8snuybc\nnijkMZhZT9kEGvG3SRIPM/zle9al9P1IzFD3u3po6/MTicVnvWP/VHmZFnbXtPDd6rOLtgC3u6aF\ng2e7CUcNYkMpk5GYwUAwQlmOnR5fZEbHkTCBx4ygONvGoea++AVBE8PnmOj11fVdGBICkRhWs4Yh\nJb2BMAdcPWkVolhI3N7QcNHSVARiOo/uO8N9Oy8cFvsELT1TXzBWAou+aDtfJJCfacHtmzy0YUgI\nxvS0S4WbjguKszjePjhqmwlw2M2EovqkojERdjOU5mUOxfwlf33DhSldIExkUPT6QvhGfPEmSmmM\n6JJdrzWhGzql+Vl0DQYXtPXj7pqW4cXTqGFQWZgJEroGw0R0g3O6gWloUjHdBVYTjMqx1wT4wlF+\nfKAFm1kQiBjYLWZCsck/rzEdTrYPEAjr6IaOzaJhN5v53m9d9PvDFOdmsOvjV6wo0T/VNkimRSMY\nNZhqKcUwJIPBGKfaB1mdZ6et/50GpBWFmQsw0vRmyQv+1VWFvNZQQM3ZHvonKYrJtGjc+54LltwX\n5L6dGzjRNsi5nnhM0pltY12RgysrCwDJr4930DCBU+NElOVl8eCtmxfMqndvXRe+cHRGs7I+f4SI\nrmNIQddgEEOKBW39uL+xB4j3Ge7xhWl0+zGJ+N1hIkVzpgggw6rhDcdfFDXA442Qk2GiPN9B12CQ\nkmw7bzb3TXoMf9SgxxdhVW4GfYEIOyoL8EdinO+Lr1N5PX6+/KtT/OATO+b8Oy8lXB4fZ7v9RI2p\nvYtgyLrAbNDWF2T72nyC0W76/VEqCjNXfDgHloHgVzkdPHDzRTx/tJ0fH2gmENGJ6QZmkyDXbubi\nsjzuubYyLfNzp6PK6WDXx68Yjn+PXcXftjafT/7v4XGVtWMpzLLw4K2bF+w9cHl8NHl8eIMzaTYe\nj10PBHVy7Wa2rs7jzsvLF/Tvdc36Ql6u66LHFx6ePSYm6bNNgjIkcXMsERd/TUBehoWYlHQNBgnH\nJFdXFRKKGRxrHZj0OAOhGHLo9dkZZo639Y963uVOXTVmutHc7SfbbqY4207nYBBjmuWUWEzyuzPd\nWM1xI4Ev37klrdJdF5MlL/gQF8b7b9zAZWsnLhRZykyV73zdxmKuWlfIKw2eSV8vmLmXR7Jo7vZT\nlpdJfqZ3ylDbOET87mOhL85376igrn2QX7/dQTBq4J/hAu1ESCA04q5Gl5BlN/MXv7eOA409nHF7\nOdTSx7neACYRfz7hoDiWwVAMs4CXTnSSaR39Vb2wJHvOY1xqVBZlMRCKYtIgx24Zt+g/Fp14WC3b\nrBGOGexv7FGCP8SyEPwEUxWKLFfWFmVCw8TPCSA3w0yG1bSgMfHKoixOtPXPTuwBXYftFfmLUn16\nz7Xr6BwMc/R837wEP2E8pgFmU/xiG4rqdA2EOOP20eUN09LjJxiVw4u7MV1Omncghp+PW+oKINNm\nYnNpzpzHuNSocjr4P++pYtdvXXRq47O8xmIbypLyhqJYzaak9jVe6iwrwV+JNHf7JxSL1bk2AtF4\niqFZ0xY0Jl7ldMzaDTLLqnHvey+gYyDI558+gQR++XYHsDDVp1VOBx9911o83hDBSGw4Bj9bdAkm\nATazhhBx47GobvBEzXncvvCouy055udEf0d9aAdfOG7mZjLFF+0X8u+ZDly3sZg1BZn88I0m2vv8\nTOZhpwnIzbQQ1SUXFjv4g+2r1ex+BErwlzhrC7LQtB40IYnqkGGG919Sxjc/fNmi5bVX17snDFFM\nhN0MV11QxCeuXcd1G4vZ/tBvRgnh1146vWBfWN2QrC/Opq0viDc8szTMkWgCsqwmNgxV1XZ7Q2RY\nTQQjOv6IMW1ozTSBLbEh40kH4ZiBxRy/C9qxrmDF3clC/KL8p9euo8nj5/C5vgmbtlxZmc+71hWm\nrZnaYqMEf4lzz7WVHG/rx+MN4cy2j2p0shghroQnf68/PFV5BBAXyIIsOzduXjU8Tu+YqdvYx6mk\nsiiLk+0DuGeYcw/xkNlAMDYcnsnLtBLVDVr7gmga+L0RhJjZ4u9ECU2aiFszI+KuWmYTDAZiKfdN\nn4zFtiuIt7bcwvNH23n+WBvnegLDC+25djO3Xbo6JQ3slwtK8Jc4VU4HX79rW9oU5CSqVTOtZqKx\n6JSCX+ywsmV1zqjeqFdUFoyqLr6isiCFox3PTAusEgTCcbHPz7TgC0fpGAgNp08mLng2bbpL3+RY\nTAKLWcNqSGK6QVSHt1p6+Juf1vLtj25fcFuMe398iI7+IJlWE398VSXb1uYtWKpvgkSSxm3bynj8\njWZeOd1Jtt3KmoIM1Wd3GoSU6dGIAeLmaYcOHVrsYSjmQWKGPxiMEokZRCeIY5gFrMq1c+f28lFW\nwQnu3nWAt8/3s3VN3oJ67Oyr6+I/X23keOvAhOOejoSHzlgsmkCIeIGZGNJ+kyaGC7QmO5PGO0V2\nZk0QiRmj7gI2lGTx3T9euAKsj3xvPwebxtcPrMqxsbU8b9GsSxb7riMdEEIcllJeMd1+aoavSCrX\nbSzmK3dewt66Ltr7gvzujGdULr7FJHA6bGwuy5lQ7IFFM1KrLMpi3VA19umOQUKx6ePuI5ksapOo\niE6kYa4ryqStL8hUwSrTUGu8waGQ1kROnQ1dfh589sSCeOzsrmnhrUmKxToHw/hc3YvmTrvYVs1L\nCSX4iqSTWDv4xp56Tnd5ERL6AhGqih3ccFEJxdk2rkpD99Iqp4NPXr+e54+2Y9EENVNUw86GhFQn\nFnA7+0PjBNw6lEqYYCZr3jaToNcfSblHVHW9m39/qX7KMfnCOh5vOGVjUCQHJfgpZKXfam6vyOfZ\no+1oQlKUbefvbtqY9pkT53sDPHOkjVA0lvTOQ/6hTkcWEwTHTO8TnbGm89zXBEgZt3wwmTQKsqwp\n94iqbelDIKc0fbOboTjbltJxKOaPEvwUsbumhf/3WhN2i0Z5fuaSs2ZOBtdtLOah20nrnqNjqW3p\nQxOSVbkZeLyRGYu+RWNKGwmrSWAzazizbVyyOpfnjnWMel435LTGbJUFmZQXZHBFRT49vsiCVZRv\nr8jn54dbEZO05gNYnZ+lFkyXAErwk0R1vZunD7ciRdz+9pdvtxPV4wuU3b64tW1NU09a9S9dCJZa\n9XPirmQwGMEE4+LsYxdmbSaNNQUZNHWPNrHTxGhLiwyLibxMK+uLHdz3vg28fKprnAdSkcOCZ0R1\nssNqwqQJSnJsOLPtlOVlYEi54LYhiXWZx99opqXXj3sgiC86+lK4Nj89WwsqRjMvwRdCfA24FYgA\nLuBPpZT9Q899Dvhz4sWC90kpfzPPsaYt1fVuPvvzY/T6I+PinDEJ3d4I/7HnNL5QDKvZlJb9SxVx\nRt6V/OLwedoHRselr6zM44w73t/WH9ZZnZ+BIUHT4kVREF9wzc2woBsGICjLs/P7F6/CmW0fXrtw\n2EyjBF8Af3vTRn68v4X2/gASwTVVhWTZzHzy+vUAixoeTFS6PvZqI12DGbx5tmf4jsZmFty0pWTB\nx6SYPfOd4b8MfG6os9XDwOeAB4QQm4m3M7wYKAP2CiE2SCnnblKSxtS29BGM6JMuahlAXyA+VzQZ\nBkIIZeiUxiTuSvoDUf7nYMtwWCfTonHH9nJePe0ejsd/4JJS6ju9PFUbwiwMQjFJWV4Gm0pz2FSa\nM+kC9Qe2lvGj/S3Dj3duKh5udN3c7R9O2xwp8Is9g04sajd3+7llayl7TnYSCOvcoewLlgzzEnwp\n5Z4RDw8Cfzj0/9uBJ6SUYaBJCNEI7AAOzOd86cr2inx+8EbTjPYNxSSakFxYom5/0517rq3k9UYP\nbX1BMqxmtqzOoTjbzgM3bxo123Z5fLg8Xnr9EewWEx+6fM20PZS/eNsWAN440821FxYNP073FMOR\n41Miv/RIZgz/z4Anh/6/mvgFIEHr0LZlyZqCTNbkZ1LX6Z3R/nkZFgqyVEZDulPldPDgrRfzvddc\n5NotZNnMwyI/UpTj5f6XzDrkkhB5hWKhmFbwhRB7gVUTPPVPUsrnhvb5J+LrWz+Z7QCEEPcC9wKs\nXbt2ti9PCw64eghEYuRlmOkfm283AXaLaYK+p4p0JBG7nk7M031mrlDADARfSvm+qZ4XQnwC+CCw\nU77j09AGrBmxW/nQtomOvwvYBXFrhemHnH4I4iZfMxF7iwbFOTaVwraEUGKuWC7MN0vn/cA/AO+V\nUo5sCf888FMhxDeIL9peCNTM51zpzFVVhVhM08/ZzRpsKcvl0+/boAQkCSxGoxRF+uDy+Djo6kHC\ntGsmijjzjeF/B7ABLwshAA5KKf9KSnlSCPEz4BTxUM9fL9cMHYjPAD92VQXf2ntmOPdaAGW5NnwR\nHZtJIxCJcWVlIf9862b1wUwCu2taePC5k+i65KWTnYBaRFxJ7K5p4Vsvn8EbiuKwm3mtIX9FFjfO\nlvlm6ayf4rkvA1+ez/GXEvft3IAz28YPX28iHDP40OXlbC3P48HnTqIJid1q5p5rK9P2A5mwgZgo\nHTAd+enBc8NNVgxd8u19Z9ixTs3yVgLV9W6++uvTDAwZywWiEWpb+hbNvG0poeyRU8xidZ2aiISo\nu70hOvpDlObZKc62Y9IEj+xt4FxPgFBU57KKfDKtJlbl2ukLRKkqcnDrtrK0+jJtefBFfJHRlaqr\n8+x86ob1aqa/jHF5fPzfF07y24bucbYXhVkWbtlayj3XrEurz+pCMFN7ZCX4K4TqejeP7G1gIBij\ntS++3JKYyfcHIqMaQyeWI/QR4anVeXa+9AeXpMVF68u/PMUr9Z5xz2lDFa7/8P6NFGfb0/4uRTE7\nXB4fD79Yx+tnusfZUiTQgHXOLP7lg5tp6wuumPi+EnzFMC6Pj7//2TEaurwEIvqcXSCLs238+x9u\nXTTRd3l8PPZqI7861kZokhUhuxksJhNZVjP5WVYeuPmiRb9IKZLDvrouvvyrOs6O8S2aCIsGNosJ\nTcD64my+9keXLmvRVw1QFEB8Zv/U4VbO9/oJzkPsAdzeMA//uo63W/s50+Vb8OyY5m4/R8/3Tyr2\nAKEYhGI63rBOlzfMQy+cZE3B4hh7rXR77GRj0gTt/cEZ7Rs1IDpkf1F7rp//738O8flbNq/4i78S\n/GVMdb2bT+8+wmAoed7ujd1+Ht17BotZW1ATOJfHx/NH23F5Jp7dCcCqQXjEnb4EOgdCHFyExbzE\n3UhNUy/uwSC/t6GY799z5YKOYbmhG5K8TAudg7NvtNLg9vPZnx/ja3906YoWfSX4y5jvvuoazmRI\nFonMGAtgSLkgJnAJ8Tx4tnvSfSSjxX4kL5/qZHV+xoJ+0Zu7/dQ09Q43NN9b52bzv/yad11QyJr8\nLDasyl7Q2HIiZ93jDQGComzb8PldHh8HXD0ISMtOZAkSd0pzEXwBRHSd2pY+JfiK5UnnwMxuf+dC\nJGZgNmlcsz71FcPN3X40IciwmGb92rAuOeP28uBzJ3nodhbsy15ZlEXHmPBDICp5tb4b6KYgy8IV\nDQULkju+u6aFXa81MRCMMBiMYgx1zMrJsFKWa6drMIQ/HLfurijM5NPv25CWohj3LNrCl355cuh9\nnDkCsJpMbK/IT83glghK8Jcx29bm09KXfNG3aFCQZeVjV1UsSDinsigLQ0picrqeUOPRpKQ8P4uu\nweCCzu6qnA5Kcmy0DUw8G+3zR2ntDSxIP9r/2NOANxglPMK/O6JDty9Cty/yzs4Rg2DUx0MvnOLI\nuX4GghEON/dxQXEW9+1Mj+rwKqeDf/7gxfQHjnHkfP+0+6/OtVGen0lxjp0PXV6elheyhUQJ/jLm\nvvddSEOXl9Y+P6GogSZAN+LplpqIN+2IzrL+WQAluXb+6r3r+eOrFmbBNuHDHo0ZdA10TNlKcCzC\nBF2DQQwpFnx290dXrOFb+xonfE4Cpzu9mLTU2ujFWzbCTN36glGd1r4A3/vtGRLRwBPtg5zp8vHt\nj25PG9EPRsaHKu1mgVnTyLKZsZjB6cjg63ct7+yc2aIEfxlT5XTwnY9tH66g3VfXxYm2QdYWZnJu\naHbZF3gn/74oy4LdqhGJSfr9EUbWNQkg0xr/Mm0uzeHqBTZ/q3I6+PSNG3izqYcub2T6FxAPW3zq\n+guJ6XJRCt9u3baap2rbhuP4YzGAZ2rbUjous0nQ54/M6iI5tpG6BNwDoZTfjcyGJo9v3LbNpTkU\nZdv46LsqlkS1+GKgBH+ZM9LpMdGiThOCDLOGlBIBCAFSwqpcO/ffuJGOgRA/eqOJxhEZMXdcVsbl\nFQWLurBX5XTw+xeX8sRbcVuF6TKP8jOt3LJ18SqEq5wOfvRnO/jyr07x23rPhB3RXJ6Z9VCYCy6P\njwNne7CZTUQj87OyKs6NF7KlC5vKcjnaOjD8+KISB399w4VK5KdBCf4KYmSLOpMm+PeXTtMf9IKM\ni/5NF6+isiiLL/3yFM09AWwmgcUkuPHiVXzzw5ct6tgTFhWbyrK5sjKfjoEQnQOhURWXZkY3HTcJ\nseiz0iqngx98Ygcuj4/H32jmJ2+2DAu/NvSep4rmbj8mITDmUVxp1uA9G5z80y3pZfr37KfezR3f\neZ269gE2leXy7KfevdhDWhIowV9hjJ3xf3tfAy63nxsvLuGWrWV85L/24xmyWQjrkk2lOWkh9gkT\nOkMKdMOgoz9Ejt0EaBhSkmE1s6HEQU1THxAPQ5hNIm1mpYkMkxs2FfPdVxvp9Ue4dVsZ9+3ckLJz\nVhZl4QvHxoVoZoPNpKWd2CdQIj97lOCvYKqcDr71ke3Dj/fVdY3y1AE405W6kMNMiS88SkpyMnir\nqZfEnL4/pGMSsLYwk3vfcwGluRmc9RwjGI6iaRp/fcP6tBOqRIP0haDK6aAwy0rMmLvg+6MGn3/6\nOE/+n6uTODLFYqEEXzFMZVEWhVmW4Rk+wNY1eYs4ojjbK/J59mg7jV1exq496hLKcjMozrZz3cZi\nvvZHl6aNO2k6YBjx0JGUTLnmkVjLyc+00B+IjlpvSOU6g2Jh0RZ7AIr0ocrp4Im/uoaLih1kmOHq\nCwrYfe/iz+yu21jMQ7dfTEGWddxzFhNk2UzDoZvrNhbztzdtVGI/xE1bSrCZNcxaXPizLNrwl14A\nZk3gsJrIyzRzaXke99+4kesvGv3e/d6FzgUftyI1JMUtUwjxd8DXAaeUslvE2189AnwACACfkFLW\nTncc5ZapmIrdNS186Zd1+IcyTvLsZj77/ovS2g4gHUi0grywxMGJtgFOtA3iC0fJsZu568q1FGbZ\nxtkI3//kEQ66eriqqnDR13AU07NgbplCiDXATcC5EZtvJt7H9kLgXcB3h34qFHMmUdWr+tjOjrt3\nvFMRPdM+sErklyfJiOF/k3gj8+dGbLsd+LGM3z4cFELkCSFKpZQdSTifYgUzUrwUs2dklpZi5TGv\nGL4Q4nagTUp5bMxTq4HzIx63Dm1TKBQKxSIx7QxfCLEXmKg65J+AzxMP58wZIcS9wL0Aa9eunc+h\nFAqFQjEF0wq+lPJ9E20XQlwCrAOOxddoKQdqhRA7gDZgzYjdy4e2TXT8XcAuiC/azmbwCoVCoZg5\ncw7pSCmPSymLpZSVUspK4mGb7VLKTuB54OMizlXAgIrfK5Yqu2ta+Juf1rK7pmWxh6JQzItUFV79\nmnhKZiPxtMw/TdF5FIqU8sXnT/CTg+dASF460Ul9p5cv3rZlsYelUMyJpAn+0Cw/8X8J/HWyjq1Q\nLDRxs7Mm/ufguREVqpL/PdDCxlXZKlNIsSRR1goKxRiq6908/OJpTnd6x9kRxCR855VGdqxTxV6K\npYeyVlAoRuDy+Hjk5QYaPb5JvWf6/BF+9EYTrgmacCgU6YwSfIViBM3dfsQ07QADUYNX69089mqj\nEn3FkkIJvkIxgsqiLIqybdOKftdAiFMdA7xwtJ19dV1K+BVLAhXDVywYLo+P5m7/qDZ01fVu9tV1\nUZBl47Zti9eOMEGV08GW1bm8fMo95X5RA1xuP9/vPcuGkmzWFWXxyevTz39foRiJEnxFytld08Iz\nta14fBHyM624B4JsKMlhW0Ue/3OghcFgFE0THGru5aE7tiyIaLo8Pg64esb16HV5fDy+v2nafrkQ\nb/Yd0XVOtg2QaTUtejtFhWI6lOArUkKiB+35vgC/fLuD6FBHjSYCALQOeKhu8GAQ92XXDEnHQHBB\nRNPl8XHbt1/HH9Exa3DDRcU8cPMmqpwODrp66AvEpj/ICMK6pK0/mDbtFBWKyVCCr0g6u2ta+PKv\n6ojEDKK6nHS2nOheJYl3rhoMRhdENO/edWDYUz9mwO8aPHz4yrVUOR1I4gtbYztrTcel5bnLenaf\nCMeZNIFuyOGwXMJrX9lVLw2U4CuSisvj4+sv1eML67N+rTcc5XxvIKXC6fL4cHsjo7YFY3L4QmPS\nwGYxEYvMfPwacGVlYVC8wj0AAA6KSURBVDKHmTYk/POfqm3lrMfPQDCK3QyleVm8Z0MR/3ughZiE\nF4/HnVOU6Kc3KktHkVQef6OZ3kB0+h0nwG42U9vSl+QRjaa52482JgMn06INz1b/Y08D0yToTIi2\nDL9JLo+Px15t5H/fbKb2XD/9wSgSCMbgbLefH+2Piz3EC9K+V+1a1PEqpkfN8BVJo7rezQtvt8/p\ntWYNMm1mtlfkJ3lUo6ksyuLS8jyOnO8H4usH/3Lr5qHF2haCEZ3Ztv3Mtpvp6A+lYLQLz6P7Gni9\noZt3byji4rJcNCEIzvBurc8fTvHoFPNFCb4iadS29JFhNRHTJd7wzBc+7WbBjRev4kPby1PefLzK\n6eDrd13K4280ca43wO9vWcXdOyrYV9dFkcNKe38Q/5DAzSaWn+oL1ULw6L4GHtnXCFJy+Hw/f3LV\nWtr7g7T1BWf0eptVyUm6o/5CiqSxvSKfnx8+T0TXETCj1EaTgC/cdvGCxn6rnA4euuOSUdsqi7Io\nybGztRzOdPno8YeRkil/CSFAk3D52vyUX6gWgtcbukFKMq0m/GGdpw+fJxg1iM7whqc/EKG63r0s\n3ovlihJ8RdK4bmMxd12xlqcOn2cgGMUX1qcUfQH8ydXp0aO2yungk9evHy4Mq2nq4acHz9EfjNDj\nixCIxuf6gnj4STcg22Ym02bi49dWLurYk8W7NxRx+Hw//rCOAXjDxowu2gkMA/bWdSnBT2OU4CuS\nym3byvjdGQ9t/aEpxcKiQX6WlRy7ZcHGNh0jG3xXOR3sWFfIY6820tTt53jbAJoATQgqC7O4+ZJV\nxHTJ9orlMbsHuG/nBgB2v3mO/mCUqG4Qm2FMSxNgMWsUZdlSOELFfFGCr0gqVU4HMX36mWHMACnT\nO/Y9ctbv9oY41T6YNhYQqeK+nRvYWp7H/U8eJTIDtbeZBQLIzTSz3pnNrdvKUj9IxZyZt+ALIf6G\neLOT/7+9u4+tqr7jOP7+9IHyUB5LK8gzFZhPEbFWxMl0gAOzyeYShGUb24xMg5u4LDhnYpyZmXM+\nzS3RoJJoJj5NUaLbVFRMNq2AwFBQpMUiT2tLUaCUFgrf/XFO8bbcPnlt77m931dCOPd3Trnf/Dj3\n29/9nnN+v2PAy2a2OGy/Gbg6bP+lmb2S6Hu56Fu1pZKtFQdb3J8B9MnJxMyYXJgX+dFx7Kg/XVwy\noYDFMyew5K1tHD7aQMWBI2RlBPMHQVDWkmBg72zOHz2I42ZMHV/AhYW+RkDUJZTwJV0KzAbOMbN6\nSQVh+xnAXOBM4FRgpaTxZtbxp3FcSlm3/TP69sqi/uDRJne49M7OICc7k2PHjdyeWWRlZPD9ScOT\nFqdr3bziURSPyaN87yE27d7P1ooa8nJ78O62auoajnNq/15cM3Vsk6duXfQlOsK/DrjTzOoBzKxx\nisHZwFNh+yeSSoFi4J0E389F3KRRA3lhw24G94X9h48yalAuU07Lo1/P7BPlm3XbP+tWte/uqvHb\nzbTTTznRFm/GU5c6Ek3444GLJd0B1AG/NrM1wDCgJOa4nWHbSSQtABYAjBw5MsFwXLJdMqGA22e3\nntQ90aeudCxxdSdtJnxJK4EhcXbdEv78IGAycD7wjKSxHQnAzJYASwCKioo69oiji6RLJhR4Uncu\ngtpM+GY2vaV9kq4DnrfgWfTVko4Dg4FdwIiYQ4eHbc65L8FLKe6rkGhJ5wXgUuBNSeOBHsBeYAWw\nTNK9BBdtxwGrE3wv59JK45oCQwf05M2Pqjh0pAEMLj97aJNFW5xrr0QT/lJgqaQPgCPA/HC0v0nS\nM8BmoAFY6HfoONd+q7ZUcuuLm8iQsbP6MI0zEwnYs/8wL2/czYJvFHrpzHVIQgnfzI4AP2xh3x3A\nHYn8+86lo7KqGh77Tzk1dUepPdJA7DR0BmzbW0t1TT33r/yYEYN6+0jftZs/aetchJRV1TDnobep\nPtT6mgIH6o6x+/PDlJRVe8J37dYNl21wLnXd+NT6NpM9BCP91paPdC4eT/jORcgne2vafWyfnCwu\nLOyeSyu6zuEJ37kIuWDs4Cave2e3/BEd5w9BuQ7yhO9chDwy/3ymn15Av5xMhvbPYer4fPJze8Q9\ntl+v6Ewt7VKDX7R1aSGVHlx6ZP75wBcxzy0eyeJnN1BZ07S237eXf3xdx/gZ47qlJ1dv5+3SarZW\nHGTHvkNkZmRyWkEug/vmcNOsr0U+6UPTeWtmnjWUx0s+PbGvd49MpsdMauZce3jCd93OA69/zAOv\nl9JwPPYelgY27vycgn45vJOCtzLOv2gM7+86wKf7DpGVIRbNGO8PXbkO84TvupWyqhqWvFXWLNkH\nGgwO1QcLrKeawvxc7p5zTsqUpVw0ecJ33UpJWTU1R1pemq/26DEyUvRWBZ+a2CUqRU995+Jra+H0\nvjlZ7Pm8rsvicS5KPOG7buXCwjz69Yz/xTVDIic7M9ILpzvXmTzhu26lMD+X5QsvoqDvF/euZwmG\nD+jFZWcO4Q9Xnu0XO13a8hq+63YK83NZfcsMVm2p5PXNFeTl9uA7E4d1qP7deFvnlNPymFc8qhOj\nda7reMJ33daXXWrxydXb+f1LHwLwxkeVAJ70XbeQUElH0kRJJZI2SForqThsl6QHJJVK2ihp0lcT\nrnOd7+3SagAG9M5u8tq5VJdoDf8u4HdmNhG4NXwNMItgWcNxwALgwQTfx7kuM+W0YAbKz2uPNnkd\nq6yqhtc/rKCsqv2zWzqXbImWdAzoF273B3aH27OBx8PlDkskDZA01Mz2JPh+znW6xvJN8xp+WVUN\nJWXVVB2sY035Z9QePQZm3DDdn3p1qSHRhL8IeEXS3QTfFqaE7cOAHTHH7QzbPOG7lLD6k32sLd9H\nVqaYVzyKVVsquX/lx3ywcz8NzW72/8WydfzlB5M86bvIazPhS1oJDImz6xZgGnCjmT0naQ7wKDC9\nIwFIWkBQ9mHkyJEd+VHnOsWNT69n+frgy+ry9bs5WNdAbX0D/92xP+6DXQfrj3HT3zeybMFkfxLW\nRVqbCd/MWkzgkh4HbghfPgs8Em7vAkbEHDo8bIv37y8BlgAUFRX5im0u6UrKgou0GYLjBu+V7+OC\nsXmtPsV7sO4I5XsPecJ3kZboRdvdwDfC7W8CW8PtFcCPw7t1JgP7vX7vUsXkcNnAxvnXzhs9iOPW\n+lhkSP/ejB7cp7NDcy4hidbwrwH+LCkLqCMszQD/AC4HSoFa4KcJvo9zXea+q84FgpH+5MI87rvq\nXP5Wsp1XN1fGPX70oF48PL/IR/cu8hJK+Gb2b+C8OO0GLEzk33YumRqTfqMLC/MY3CebvYearjo1\nsE8210wt9GTvUoLPpeNcOxTm5/L0tVMYM6g3EMy8mZ+bzRlD+p0oATkXdT61gnPtVJify5uLLz1x\nP74RjPx9dO9ShSd85zrIFyJxqcpLOs45lyY84TvnXJrwhO+cc2nCE75zzqUJT/jOOZcmPOE751ya\nkLUxR0hXklQFbE92HMBgYG+yg+gAj7fzpVrMHm/ni1LMo8wsv62DIpXwo0LSWjMrSnYc7eXxdr5U\ni9nj7XypGLOXdJxzLk14wnfOuTThCT++JckOoIM83s6XajF7vJ0v5WL2Gr5zzqUJH+E751ya8IQf\nQ9LTkjaEf8olbQjbR0s6HLPvoWTHCiDpNkm7YuK6PGbfzZJKJW2R9K1kxtlI0p8kfSRpo6TlkgaE\n7ZHsXwBJM8M+LJX0m2TH05ykEZLelLRZ0iZJN4TtLZ4bURB+vt4PY1sbtg2S9JqkreHfA5MdJ4Ck\nCTH9uEHSAUmLot7H8XhJpwWS7iFYi/d2SaOBl8zsrORG1ZSk24AaM7u7WfsZwJNAMXAqsBIYb2bH\nujzIpnFdBrxhZg2S/ghgZjdFuH8zgY+BGcBOYA0wz8w2JzWwGJKGAkPNbJ2kvsB7wHeBOcQ5N6JC\nUjlQZGZ7Y9ruAvaZ2Z3hL9eBZnZTsmKMJzwndgEXECzdGtk+jsdH+HFIEsEH5slkx/IlzQaeMrN6\nM/uEYG3h4iTHhJm9amYN4csSYHgy42mHYqDUzLaZ2RHgKYK+jQwz22Nm68Ltg8CHwLDkRvWlzQYe\nC7cfI/jFFTXTgDIzi8IDoh3mCT++i4EKM9sa0zZG0npJb0m6OFmBxXF9WCJZGvMVeBiwI+aYnUQv\nCfwM+GfM6yj2byr04wnhN6VzgXfDpnjnRlQY8Kqk9yQtCNtOMbM94fb/gFOSE1qr5tJ0IBjlPj5J\n2iV8SSslfRDnT+zIbR5N/1P3ACPN7FzgV8AySf0iEO+DQCEwMYzxnq6IqTXt6V9JtwANwBNhU9L6\nt7uQlAs8BywyswNE8Nxo5utmNgmYBSyUNDV2pwW15kjVmyX1AK4Ang2bot7HJ0m7JQ7NbHpr+yVl\nAVcC58X8TD1QH26/J6kMGA+s7cRQG9+71XgbSXoYeCl8uQsYEbN7eNjW6drRvz8Bvg1MCz/USe3f\nNiStHztCUjZBsn/CzJ4HMLOKmP2x50YkmNmu8O9KScsJymcVkoaa2Z7w2kRlUoM82SxgXWPfRr2P\n40m7EX47TAc+MrOdjQ2S8sOLNUgaC4wDtiUpvhPCD0Wj7wEfhNsrgLmSciSNIYh3dVfH15ykmcBi\n4Aozq41pj2T/ElykHSdpTDi6m0vQt5ERXm96FPjQzO6NaW/p3Eg6SX3CC8xI6gNcRhDfCmB+eNh8\n4MXkRNiiJt/8o9zHLUm7EX47NK/RAUwFbpd0FDgOXGtm+7o8spPdJWkiwVffcuDnAGa2SdIzwGaC\n0snCZN+hE/orkAO8FuQpSszsWiLav+HdRNcDrwCZwFIz25TksJq7CPgR8L7C24iB3wLz4p0bEXEK\nsDw8B7KAZWb2L0lrgGckXU0wa+6cJMbYRPiLaQZN+zHu5y/K/LZM55xLE17Scc65NOEJ3znn0oQn\nfOecSxOe8J1zLk14wnfOuTThCd8559KEJ3znnEsTnvCdcy5N/B9agswW5uYItgAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe336be6c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.scatter(tsne_z[:, 0], tsne_z[:, 1], s=10, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save learning results\n",
    "sio.savemat(\"vanilla.mat\", tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
