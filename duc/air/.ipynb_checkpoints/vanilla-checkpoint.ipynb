{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.manifold import TSNE\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptb import PTB\n",
    "from model import RNNVAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device configuration\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penn TreeBank (PTB) dataset\n",
    "data_path = '../data'\n",
    "max_len = 96\n",
    "splits = ['train', 'valid', 'test']\n",
    "datasets = {split: PTB(root=data_path, split=split) for split in splits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "batch_size = 32\n",
    "dataloaders = {split: DataLoader(datasets[split],\n",
    "                                 batch_size=batch_size,\n",
    "                                 shuffle=split=='train',\n",
    "                                 num_workers=cpu_count(),\n",
    "                                 pin_memory=torch.cuda.is_available())\n",
    "                                 for split in splits}\n",
    "symbols = datasets['train'].symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNVAE(\n",
      "  (encoder): LSTMEncoder(\n",
      "    (embedding): Embedding(10002, 300, padding_idx=0)\n",
      "    (rnn): LSTM(300, 256, batch_first=True)\n",
      "    (output): Linear(in_features=512, out_features=4, bias=True)\n",
      "  )\n",
      "  (embedding): Embedding(10002, 300, padding_idx=0)\n",
      "  (init_h): Linear(in_features=2, out_features=256, bias=True)\n",
      "  (init_c): Linear(in_features=2, out_features=256, bias=True)\n",
      "  (rnn): LSTM(300, 256, batch_first=True)\n",
      "  (output): Linear(in_features=256, out_features=10002, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# RNNVAE model\n",
    "embedding_size = 300\n",
    "hidden_size = 256\n",
    "latent_dim = 2\n",
    "dropout_rate = 0.5\n",
    "model = RNNVAE(vocab_size=datasets['train'].vocab_size,\n",
    "               embed_size=embedding_size,\n",
    "               time_step=max_len,\n",
    "               hidden_size=hidden_size,\n",
    "               z_dim=latent_dim,\n",
    "               dropout_rate=dropout_rate,\n",
    "               bos_idx=symbols['<bos>'],\n",
    "               eos_idx=symbols['<eos>'],\n",
    "               pad_idx=symbols['<pad>'])\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder to save model\n",
    "save_path = 'vanilla'\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function\n",
    "learning_rate = 0.001\n",
    "criterion = nn.NLLLoss(size_average=False, ignore_index=symbols['<pad>'])\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# negative log likelihood\n",
    "def NLL(logp, target, length):\n",
    "    target = target[:, :torch.max(length).item()].contiguous().view(-1)\n",
    "    logp = logp.view(-1, logp.size(-1))\n",
    "    return criterion(logp, target)\n",
    "\n",
    "# KL divergence\n",
    "def KL_div(mu, logvar):\n",
    "    return -0.5 * torch.sum(1. + logvar - mu.pow(2) - logvar.exp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training setting\n",
    "epoch = 20\n",
    "print_every = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Batch 0000/1315, ELBO-Loss 176.2793, NLL-Loss 176.2487, KL-Loss 0.0306, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 137.3026, NLL-Loss 137.2905, KL-Loss 0.0121, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 131.1157, NLL-Loss 131.1116, KL-Loss 0.0041, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 145.3204, NLL-Loss 145.3178, KL-Loss 0.0026, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 130.7767, NLL-Loss 130.7741, KL-Loss 0.0026, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 142.1345, NLL-Loss 142.1327, KL-Loss 0.0019, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 133.4554, NLL-Loss 133.4541, KL-Loss 0.0013, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 139.0087, NLL-Loss 139.0070, KL-Loss 0.0017, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 132.7210, NLL-Loss 132.7196, KL-Loss 0.0015, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 131.0713, NLL-Loss 131.0698, KL-Loss 0.0016, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 123.7692, NLL-Loss 123.7679, KL-Loss 0.0013, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 114.7688, NLL-Loss 114.7678, KL-Loss 0.0011, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 125.7784, NLL-Loss 125.7770, KL-Loss 0.0014, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 133.1618, NLL-Loss 133.1606, KL-Loss 0.0012, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 125.6035, NLL-Loss 125.6021, KL-Loss 0.0015, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 137.3528, NLL-Loss 137.3509, KL-Loss 0.0020, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 157.1034, NLL-Loss 157.1017, KL-Loss 0.0018, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 110.3463, NLL-Loss 110.3446, KL-Loss 0.0017, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 126.9634, NLL-Loss 126.9619, KL-Loss 0.0015, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 99.7819, NLL-Loss 99.7808, KL-Loss 0.0011, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 133.4864, NLL-Loss 133.4846, KL-Loss 0.0018, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 141.8893, NLL-Loss 141.8873, KL-Loss 0.0020, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 119.4626, NLL-Loss 119.4610, KL-Loss 0.0016, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 111.9541, NLL-Loss 111.9523, KL-Loss 0.0018, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 118.1453, NLL-Loss 118.1438, KL-Loss 0.0014, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 115.7334, NLL-Loss 115.7321, KL-Loss 0.0014, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 111.3781, NLL-Loss 111.3760, KL-Loss 0.0021, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 101.2507, NLL-Loss 101.2495, KL-Loss 0.0013, KL-Weight 1.0000\n",
      "TRAIN Epoch 00/20, ELBO 129.7404, NLL 129.7375, KL 0.0029, PPL 468.4762\n",
      "VALID Epoch 00/20, ELBO 118.6122, NLL 118.6109, KL 0.0013, PPL 292.5476\n",
      "TEST Epoch 00/20, ELBO 117.4672, NLL 117.4659, KL 0.0013, PPL 274.7321\n",
      "Model saved at vanilla/E00.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 127.8718, NLL-Loss 127.8706, KL-Loss 0.0012, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 134.5261, NLL-Loss 134.5240, KL-Loss 0.0021, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 126.9121, NLL-Loss 126.9104, KL-Loss 0.0017, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 127.6507, NLL-Loss 127.6496, KL-Loss 0.0011, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 113.4032, NLL-Loss 113.4023, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 118.8131, NLL-Loss 118.8116, KL-Loss 0.0015, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 121.1531, NLL-Loss 121.1523, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 111.8488, NLL-Loss 111.8474, KL-Loss 0.0013, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 106.4288, NLL-Loss 106.4275, KL-Loss 0.0013, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 121.3924, NLL-Loss 121.3914, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 98.6651, NLL-Loss 98.6639, KL-Loss 0.0012, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 95.0479, NLL-Loss 95.0466, KL-Loss 0.0013, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 114.9186, NLL-Loss 114.9181, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 113.0101, NLL-Loss 113.0094, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 114.2996, NLL-Loss 114.2985, KL-Loss 0.0011, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 121.1750, NLL-Loss 121.1741, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 116.7747, NLL-Loss 116.7738, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 110.9389, NLL-Loss 110.9383, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 110.7591, NLL-Loss 110.7583, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 112.3100, NLL-Loss 112.3092, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 99.0030, NLL-Loss 99.0021, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 106.1211, NLL-Loss 106.1203, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 115.8064, NLL-Loss 115.8055, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 121.4119, NLL-Loss 121.4111, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 114.9429, NLL-Loss 114.9421, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 120.8794, NLL-Loss 120.8783, KL-Loss 0.0011, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 119.3360, NLL-Loss 119.3353, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 100.3155, NLL-Loss 100.3150, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Epoch 01/20, ELBO 116.8002, NLL 116.7992, KL 0.0010, PPL 253.7161\n",
      "VALID Epoch 01/20, ELBO 113.8787, NLL 113.8782, KL 0.0005, PPL 233.2344\n",
      "TEST Epoch 01/20, ELBO 112.7475, NLL 112.7470, KL 0.0005, PPL 219.2462\n",
      "Model saved at vanilla/E01.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 111.1854, NLL-Loss 111.1848, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 115.8071, NLL-Loss 115.8062, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 109.5666, NLL-Loss 109.5655, KL-Loss 0.0011, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 112.8144, NLL-Loss 112.8138, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 115.5015, NLL-Loss 115.5008, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 122.7304, NLL-Loss 122.7299, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 114.5187, NLL-Loss 114.5179, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 126.2395, NLL-Loss 126.2392, KL-Loss 0.0003, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 133.2377, NLL-Loss 133.2373, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 118.5639, NLL-Loss 118.5634, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 113.9836, NLL-Loss 113.9830, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 118.2351, NLL-Loss 118.2346, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 105.3947, NLL-Loss 105.3940, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 106.0148, NLL-Loss 106.0140, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 102.0759, NLL-Loss 102.0751, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 112.6160, NLL-Loss 112.6156, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 94.7000, NLL-Loss 94.6994, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 112.2987, NLL-Loss 112.2979, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 121.9065, NLL-Loss 121.9058, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 105.1274, NLL-Loss 105.1271, KL-Loss 0.0003, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 100.3974, NLL-Loss 100.3968, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 113.5856, NLL-Loss 113.5851, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 90.8932, NLL-Loss 90.8925, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 126.3510, NLL-Loss 126.3503, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 119.2656, NLL-Loss 119.2651, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 97.9592, NLL-Loss 97.9584, KL-Loss 0.0008, KL-Weight 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Batch 1300/1315, ELBO-Loss 111.3552, NLL-Loss 111.3546, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 110.6116, NLL-Loss 110.6113, KL-Loss 0.0003, KL-Weight 1.0000\n",
      "TRAIN Epoch 02/20, ELBO 111.8283, NLL 111.8276, KL 0.0007, PPL 200.4506\n",
      "VALID Epoch 02/20, ELBO 111.5242, NLL 111.5237, KL 0.0005, PPL 208.3713\n",
      "TEST Epoch 02/20, ELBO 110.3886, NLL 110.3881, KL 0.0005, PPL 195.8649\n",
      "Model saved at vanilla/E02.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 108.3616, NLL-Loss 108.3612, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 112.6370, NLL-Loss 112.6361, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 116.0280, NLL-Loss 116.0275, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 114.9816, NLL-Loss 114.9812, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 99.7936, NLL-Loss 99.7930, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 106.5426, NLL-Loss 106.5420, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 90.9373, NLL-Loss 90.9364, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 92.1907, NLL-Loss 92.1900, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 100.1435, NLL-Loss 100.1428, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 98.0747, NLL-Loss 98.0738, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 108.2745, NLL-Loss 108.2740, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 93.4539, NLL-Loss 93.4533, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 124.3819, NLL-Loss 124.3814, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 105.7313, NLL-Loss 105.7309, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 117.1698, NLL-Loss 117.1693, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 109.5894, NLL-Loss 109.5891, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 97.0203, NLL-Loss 97.0199, KL-Loss 0.0003, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 107.1227, NLL-Loss 107.1221, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 97.8143, NLL-Loss 97.8140, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 95.6739, NLL-Loss 95.6733, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 96.1328, NLL-Loss 96.1322, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 105.3371, NLL-Loss 105.3366, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 113.7158, NLL-Loss 113.7151, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 121.1751, NLL-Loss 121.1744, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 110.8199, NLL-Loss 110.8196, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 123.5779, NLL-Loss 123.5773, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 110.9022, NLL-Loss 110.9013, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 89.1160, NLL-Loss 89.1152, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Epoch 03/20, ELBO 108.5502, NLL 108.5495, KL 0.0007, PPL 171.6032\n",
      "VALID Epoch 03/20, ELBO 110.0936, NLL 110.0924, KL 0.0012, PPL 194.5708\n",
      "TEST Epoch 03/20, ELBO 109.0049, NLL 109.0037, KL 0.0012, PPL 183.3210\n",
      "Model saved at vanilla/E03.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 116.2756, NLL-Loss 116.2744, KL-Loss 0.0012, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 126.2331, NLL-Loss 126.2325, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 106.2912, NLL-Loss 106.2907, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 109.9604, NLL-Loss 109.9600, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 99.2793, NLL-Loss 99.2788, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 87.4769, NLL-Loss 87.4763, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 104.6228, NLL-Loss 104.6222, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 105.3728, NLL-Loss 105.3725, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 110.4263, NLL-Loss 110.4260, KL-Loss 0.0003, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 94.7492, NLL-Loss 94.7485, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 111.2349, NLL-Loss 111.2347, KL-Loss 0.0002, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 113.5868, NLL-Loss 113.5864, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 106.4522, NLL-Loss 106.4510, KL-Loss 0.0011, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 104.8510, NLL-Loss 104.8503, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 127.5932, NLL-Loss 127.5928, KL-Loss 0.0003, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 122.8867, NLL-Loss 122.8861, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 104.4777, NLL-Loss 104.4772, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 89.3992, NLL-Loss 89.3980, KL-Loss 0.0012, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 116.0839, NLL-Loss 116.0830, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 104.9919, NLL-Loss 104.9914, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 104.1293, NLL-Loss 104.1288, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 111.1691, NLL-Loss 111.1684, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 89.1172, NLL-Loss 89.1161, KL-Loss 0.0011, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 113.7937, NLL-Loss 113.7930, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 100.8293, NLL-Loss 100.8287, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 106.9516, NLL-Loss 106.9501, KL-Loss 0.0014, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 101.0113, NLL-Loss 101.0102, KL-Loss 0.0010, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 118.4179, NLL-Loss 118.4169, KL-Loss 0.0010, KL-Weight 1.0000\n",
      "TRAIN Epoch 04/20, ELBO 106.0793, NLL 106.0786, KL 0.0007, PPL 152.6373\n",
      "VALID Epoch 04/20, ELBO 109.4214, NLL 109.4205, KL 0.0009, PPL 188.4115\n",
      "TEST Epoch 04/20, ELBO 108.1496, NLL 108.1488, KL 0.0008, PPL 175.9791\n",
      "Model saved at vanilla/E04.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 101.1256, NLL-Loss 101.1249, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 101.8023, NLL-Loss 101.8011, KL-Loss 0.0013, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 89.1482, NLL-Loss 89.1473, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 101.8568, NLL-Loss 101.8557, KL-Loss 0.0011, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 115.5978, NLL-Loss 115.5968, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 99.8289, NLL-Loss 99.8275, KL-Loss 0.0014, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 94.6406, NLL-Loss 94.6395, KL-Loss 0.0011, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 105.1268, NLL-Loss 105.1254, KL-Loss 0.0014, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 103.9876, NLL-Loss 103.9867, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 126.3802, NLL-Loss 126.3794, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 91.1030, NLL-Loss 91.1019, KL-Loss 0.0011, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 107.8086, NLL-Loss 107.8077, KL-Loss 0.0010, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 102.9336, NLL-Loss 102.9329, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 105.2194, NLL-Loss 105.2181, KL-Loss 0.0013, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 102.6820, NLL-Loss 102.6798, KL-Loss 0.0022, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 106.1276, NLL-Loss 106.1266, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 97.1280, NLL-Loss 97.1269, KL-Loss 0.0012, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 108.9912, NLL-Loss 108.9902, KL-Loss 0.0010, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 109.4728, NLL-Loss 109.4719, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 123.5228, NLL-Loss 123.5211, KL-Loss 0.0017, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 119.9474, NLL-Loss 119.9468, KL-Loss 0.0006, KL-Weight 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN Batch 1050/1315, ELBO-Loss 98.9857, NLL-Loss 98.9848, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 95.9790, NLL-Loss 95.9777, KL-Loss 0.0013, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 110.1893, NLL-Loss 110.1884, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 117.2894, NLL-Loss 117.2880, KL-Loss 0.0013, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 102.8723, NLL-Loss 102.8713, KL-Loss 0.0010, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 90.3957, NLL-Loss 90.3949, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 115.8133, NLL-Loss 115.8128, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Epoch 05/20, ELBO 104.1027, NLL 104.1016, KL 0.0011, PPL 138.9837\n",
      "VALID Epoch 05/20, ELBO 108.8868, NLL 108.8859, KL 0.0009, PPL 183.6503\n",
      "TEST Epoch 05/20, ELBO 107.5780, NLL 107.5771, KL 0.0009, PPL 171.2349\n",
      "Model saved at vanilla/E05.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 112.3991, NLL-Loss 112.3984, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 109.5667, NLL-Loss 109.5658, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 103.9229, NLL-Loss 103.9221, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 93.5947, NLL-Loss 93.5942, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 100.7293, NLL-Loss 100.7286, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 115.8305, NLL-Loss 115.8298, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 87.7340, NLL-Loss 87.7331, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 77.8355, NLL-Loss 77.8344, KL-Loss 0.0011, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 85.1943, NLL-Loss 85.1935, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 99.7457, NLL-Loss 99.7452, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 104.3126, NLL-Loss 104.3120, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 103.8725, NLL-Loss 103.8718, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 98.5344, NLL-Loss 98.5330, KL-Loss 0.0014, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 112.9297, NLL-Loss 112.9292, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 98.7413, NLL-Loss 98.7404, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 114.5065, NLL-Loss 114.5057, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 78.6100, NLL-Loss 78.6086, KL-Loss 0.0014, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 117.4566, NLL-Loss 117.4559, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 99.5899, NLL-Loss 99.5889, KL-Loss 0.0010, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 87.6550, NLL-Loss 87.6544, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 110.2585, NLL-Loss 110.2573, KL-Loss 0.0012, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 85.1729, NLL-Loss 85.1714, KL-Loss 0.0015, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 113.6954, NLL-Loss 113.6943, KL-Loss 0.0010, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 99.3608, NLL-Loss 99.3594, KL-Loss 0.0014, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 103.6626, NLL-Loss 103.6615, KL-Loss 0.0011, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 102.2827, NLL-Loss 102.2816, KL-Loss 0.0011, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 109.0423, NLL-Loss 109.0417, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 91.2696, NLL-Loss 91.2683, KL-Loss 0.0012, KL-Weight 1.0000\n",
      "TRAIN Epoch 06/20, ELBO 102.4291, NLL 102.4283, KL 0.0009, PPL 128.3861\n",
      "VALID Epoch 06/20, ELBO 108.6721, NLL 108.6710, KL 0.0011, PPL 181.7707\n",
      "TEST Epoch 06/20, ELBO 107.1929, NLL 107.1918, KL 0.0011, PPL 168.1091\n",
      "Model saved at vanilla/E06.pkl\n",
      "\n",
      "TRAIN Batch 0000/1315, ELBO-Loss 109.0988, NLL-Loss 109.0976, KL-Loss 0.0012, KL-Weight 1.0000\n",
      "TRAIN Batch 0050/1315, ELBO-Loss 98.8231, NLL-Loss 98.8221, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0100/1315, ELBO-Loss 93.9678, NLL-Loss 93.9666, KL-Loss 0.0012, KL-Weight 1.0000\n",
      "TRAIN Batch 0150/1315, ELBO-Loss 90.4572, NLL-Loss 90.4563, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0200/1315, ELBO-Loss 96.7861, NLL-Loss 96.7856, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0250/1315, ELBO-Loss 88.5764, NLL-Loss 88.5759, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0300/1315, ELBO-Loss 85.6631, NLL-Loss 85.6626, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 0350/1315, ELBO-Loss 91.4635, NLL-Loss 91.4627, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 0400/1315, ELBO-Loss 107.1892, NLL-Loss 107.1887, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 0450/1315, ELBO-Loss 96.6381, NLL-Loss 96.6375, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0500/1315, ELBO-Loss 108.8888, NLL-Loss 108.8884, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0550/1315, ELBO-Loss 90.1472, NLL-Loss 90.1465, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0600/1315, ELBO-Loss 95.0758, NLL-Loss 95.0753, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 0650/1315, ELBO-Loss 116.1125, NLL-Loss 116.1116, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 0700/1315, ELBO-Loss 92.4066, NLL-Loss 92.4059, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 0750/1315, ELBO-Loss 102.3263, NLL-Loss 102.3260, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 0800/1315, ELBO-Loss 99.1981, NLL-Loss 99.1977, KL-Loss 0.0003, KL-Weight 1.0000\n",
      "TRAIN Batch 0850/1315, ELBO-Loss 115.4530, NLL-Loss 115.4524, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0900/1315, ELBO-Loss 101.0703, NLL-Loss 101.0697, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 0950/1315, ELBO-Loss 92.6700, NLL-Loss 92.6693, KL-Loss 0.0008, KL-Weight 1.0000\n",
      "TRAIN Batch 1000/1315, ELBO-Loss 108.3455, NLL-Loss 108.3450, KL-Loss 0.0005, KL-Weight 1.0000\n",
      "TRAIN Batch 1050/1315, ELBO-Loss 79.7812, NLL-Loss 79.7806, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 1100/1315, ELBO-Loss 110.3128, NLL-Loss 110.3121, KL-Loss 0.0007, KL-Weight 1.0000\n",
      "TRAIN Batch 1150/1315, ELBO-Loss 102.1473, NLL-Loss 102.1467, KL-Loss 0.0006, KL-Weight 1.0000\n",
      "TRAIN Batch 1200/1315, ELBO-Loss 120.8501, NLL-Loss 120.8497, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 1250/1315, ELBO-Loss 94.9961, NLL-Loss 94.9958, KL-Loss 0.0004, KL-Weight 1.0000\n",
      "TRAIN Batch 1300/1315, ELBO-Loss 111.7940, NLL-Loss 111.7931, KL-Loss 0.0009, KL-Weight 1.0000\n",
      "TRAIN Batch 1314/1315, ELBO-Loss 93.7530, NLL-Loss 93.7527, KL-Loss 0.0003, KL-Weight 1.0000\n",
      "TRAIN Epoch 07/20, ELBO 101.0131, NLL 101.0124, KL 0.0007, PPL 120.0528\n"
     ]
    }
   ],
   "source": [
    "# training interface\n",
    "step = 0\n",
    "tracker = {'ELBO': [], 'NLL': [], 'KL': [], 'KL_weight': []}\n",
    "start_time = time.time()\n",
    "for ep in range(epoch):\n",
    "    # learning rate decay\n",
    "    if ep >= 10 and ep % 2 == 0:\n",
    "        learning_rate = learning_rate * 0.5\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "\n",
    "    for split in splits:\n",
    "        dataloader = dataloaders[split]\n",
    "        model.train() if split == 'train' else model.eval()\n",
    "        totals = {'ELBO': 0., 'NLL': 0., 'KL': 0., 'words': 0}\n",
    "\n",
    "        for itr, (enc_inputs, dec_inputs, targets, lengths) in enumerate(dataloader):\n",
    "            bsize = enc_inputs.size(0)\n",
    "            enc_inputs = enc_inputs.to(device)\n",
    "            dec_inputs = dec_inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "            lengths = lengths.to(device)\n",
    "\n",
    "            # forward\n",
    "            logp, mu, logvar = model(enc_inputs, dec_inputs, lengths)\n",
    "\n",
    "            # calculate loss\n",
    "            NLL_loss = NLL(logp, targets, lengths + 1)\n",
    "            KL_loss = KL_div(mu, logvar)\n",
    "            KL_weight = 1.0\n",
    "            loss = (NLL_loss + KL_weight * KL_loss) / bsize\n",
    "\n",
    "            # cumulate\n",
    "            totals['ELBO'] += loss.item() * bsize\n",
    "            totals['NLL'] += NLL_loss.item()\n",
    "            totals['KL'] += KL_loss.item()\n",
    "            totals['words'] += torch.sum(lengths).item()\n",
    "\n",
    "            # backward and optimize\n",
    "            if split == 'train':\n",
    "                step += 1\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "                optimizer.step()\n",
    "\n",
    "                # track\n",
    "                tracker['ELBO'].append(loss.item())\n",
    "                tracker['NLL'].append(NLL_loss.item() / bsize)\n",
    "                tracker['KL'].append(KL_loss.item() / bsize)\n",
    "                tracker['KL_weight'].append(KL_weight)\n",
    "\n",
    "                # print statistics\n",
    "                if itr % print_every == 0 or itr + 1 == len(dataloader):\n",
    "                    print(\"%s Batch %04d/%04d, ELBO-Loss %.4f, \"\n",
    "                          \"NLL-Loss %.4f, KL-Loss %.4f, KL-Weight %.4f\"\n",
    "                          % (split.upper(), itr, len(dataloader),\n",
    "                             tracker['ELBO'][-1], tracker['NLL'][-1],\n",
    "                             tracker['KL'][-1], tracker['KL_weight'][-1]))\n",
    "\n",
    "        samples = len(datasets[split])\n",
    "        print(\"%s Epoch %02d/%02d, ELBO %.4f, NLL %.4f, KL %.4f, PPL %.4f\"\n",
    "              % (split.upper(), ep, epoch, totals['ELBO'] / samples,\n",
    "                 totals['NLL'] / samples, totals['KL'] / samples,\n",
    "                 math.exp(totals['NLL'] / totals['words'])))\n",
    "\n",
    "    # save checkpoint\n",
    "    checkpoint_path = os.path.join(save_path, \"E%02d.pkl\" % ep)\n",
    "    torch.save(model.state_dict(), checkpoint_path)\n",
    "    print(\"Model saved at %s\\n\" % checkpoint_path)\n",
    "end_time = time.time()\n",
    "print('Total cost time',\n",
    "      time.strftime(\"%H hr %M min %S sec\", time.gmtime(end_time - start_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot KL curve\n",
    "fig, ax1 = plt.subplots()\n",
    "lns1 = ax1.plot(tracker['KL_weight'], 'b', label='KL term weight')\n",
    "ax1.set_ylim([-0.05, 1.05])\n",
    "ax1.set_xlabel('Step')\n",
    "ax1.set_ylabel('KL term weight')\n",
    "ax2 = ax1.twinx()\n",
    "lns2 = ax2.plot(tracker['KL'], 'r', label='KL term value')\n",
    "ax2.set_ylabel('KL term value')\n",
    "lns = lns1 + lns2\n",
    "labs = [l.get_label() for l in lns]\n",
    "ax1.legend(lns, labs, bbox_to_anchor=(0., 1.02, 1., .102),\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent space visualization\n",
    "features = np.empty([len(datasets['test']), latent_dim])\n",
    "for itr, (enc_inputs, dec_inputs, _, lengths) in enumerate(dataloaders['test']):\n",
    "    enc_inputs = enc_inputs.to(device)\n",
    "    dec_inputs = dec_inputs.to(device)\n",
    "    lengths = lengths.to(device)\n",
    "    _, mu, _ = model(enc_inputs, dec_inputs, lengths)\n",
    "    start, end = batch_size * itr, batch_size * (itr + 1)\n",
    "    features[start:end] = mu.data.cpu().numpy()\n",
    "tsne_z = TSNE(n_components=2).fit_transform(features)\n",
    "tracker['z'] = tsne_z\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(tsne_z[:, 0], tsne_z[:, 1], s=25, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save learning results\n",
    "sio.savemat(\"vanilla.mat\", tracker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
